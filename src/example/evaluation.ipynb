{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7f5b8d26-e301-49fd-b2bb-a185310027f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os, sys\n",
    "#from time import time\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "#from torch.cuda.amp import GradScaler, autocast\n",
    "#from torch.utils.data._utils.collate import default_collate\n",
    "#import copy\n",
    "#from time import time\n",
    "#import wandb\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Tuple\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from dataset import AEDataset\n",
    "from trainer import Trainer, WeakSupervisionTrainer\n",
    "from model import DualBranchAE\n",
    "from utils import *\n",
    "from losses import MSELoss\n",
    "from pretrainer import PreTrainer\n",
    "from torchmetrics.classification import BinaryROC\n",
    "from scipy import ndimage\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cc02d84e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# auto reload changes in .py files\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "211305c3-326d-4c47-bbec-5087737b3390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %cd example/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb22710-307a-4146-8bdd-57bba48aad1e",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "We currently work on the HPC data and within this, we built two different segmentation tasks. Further details are in the paper https://cg.cs.uni-bonn.de/backend/v1/files/publications/torayev-vcbm2020.pdf. Neither the whole dataset nor the model are in this repo. We will set you up once you started your work and give your access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3c199b3f-5e9b-4d46-acdb-3770417afc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# which tasks are used is handled by \"set\". 1 is a binary task for debugging, 2 is multi-class \n",
    "# and so is 3 but with asymmetric classes w.r.t. the saggital plane (harder). Details for \n",
    "# set 2 and 3 are in the paper.\n",
    "# 'modality' handles the target provided by __getitem__. Options are reconstruction and segmentation.\n",
    "# When segmentation is selected, the labels are taken from the annotations attribute. This is also where\n",
    "# the user-model interacts with the dataset. Ground truth masks are in the label attribute. All other parameters are\n",
    "# from past experiments and alter the behaviour. This project has been around for a while, so some are not used anymore.\n",
    "\n",
    "# normalize is usually set to true. Simply normalizes the input. Augment is legacy, we didn't have much success\n",
    "# with data augmentation. balance takes care of data balancing during a batch. Some classes are under-\n",
    "# represented so we show them to the model more often. It helps quite a bit during training so consider \n",
    "# integrating it. We can talk about how this is done in detail once you start. init defines how the user-model behaves. \n",
    "# We considered different behaviours w.r.t. to annotation style and quantity and such. \n",
    "# To_gpu moves ALL data to GPU. Since we only work on a single volume (i.e. couple hundred slices) \n",
    "# we move everything to GPU and avoid latency in dataloading. Takes a hefty chunk out of the VRAM though \n",
    "# but makes things faster.\n",
    "\n",
    "# Feel free to re-write anything you want. This is partly dated code that could use a re-write anyways.\n",
    "\n",
    "# Example:\n",
    "# make a config first. This handles globals and is used through-out the script. Many things that were tried in\n",
    "# experiments later have not yet made it into the config, but most have.\n",
    "\n",
    "cfg = {\n",
    "    # CONFIG\n",
    "    'name': 'location-unsupervised',\n",
    "    'project': 'IDVR-localization_pretrain',\n",
    "    'log': False,\n",
    "    'rank': 0,\n",
    "    \n",
    "    # DATA\n",
    "    'data_dir': '../../../data/784565/Diffusion/',\n",
    "    'data_path': '../../../data/784565/Diffusion/data.nii',\n",
    "    'active_mask_path': '../../../data/784565/Diffusion/nodif_brain_mask.nii.gz',\n",
    "    \n",
    "    # SELF SUPERVISED PRE-TRAINING\n",
    "    's_n_epochs': 20,\n",
    "    's_batch_size': 16, # default: 8\n",
    "    's_lr': 5e-4, #1e-4, 1e-5        \n",
    "    \n",
    "    # TRAINING WITH WEAK SUPERVISION\n",
    "    'p_n_epochs': 100,\n",
    "    'w_n_epochs': 10,\n",
    "    'w_batch_size': 2,\n",
    "    'w_lr': 5e-4,    #5e-5 \n",
    "    'w_eval_freq': 100,\n",
    "    \n",
    "    # RANDOM FOREST\n",
    "    'min_samples_leaf': 8,\n",
    "    \n",
    "    # USER MODEL\n",
    "    'init_voxels': 200,\n",
    "    'refinement_voxels': 200,\n",
    "    'num_interactions': 10,\n",
    "    'brush' : True,\n",
    "    'slice_selection' : 'mean',\n",
    "    'voxel_selection' : 'max'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "66666ae2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid slice selection method. Choose between \"mean\" and \"max\".",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m balance \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#dataset = AEDataset(cfg, modality='segmentation', normalize=True,\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#                    set=2, augment=False, balance=balance, init='per_class', to_gpu=False)\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mAEDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodality\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msegmentation\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;28;43mset\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maugment\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbalance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbalance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mthree_slices\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_gpu\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# currently, there are no annotations. We can also enforce this with clear_annotations() at any point\u001b[39;00m\n\u001b[0;32m      9\u001b[0m dataset\u001b[38;5;241m.\u001b[39mclear_annotation()\n",
      "File \u001b[1;32mc:\\Users\\Golo\\Documents\\Uni\\Bachelorarbeit\\Interactive-DVR\\src\\example\\..\\dataset.py:67\u001b[0m, in \u001b[0;36mAEDataset.__init__\u001b[1;34m(self, cfg, modality, mode, set, normalize, augment, localize, balance, to_gpu, init, smooth_label)\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtract_masks[\u001b[38;5;241m5\u001b[39m:]\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m#if cfg['log']:\u001b[39;00m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;66;03m#    wandb.config.update({'labels': cfg['labels']})\u001b[39;00m\n\u001b[1;32m---> 67\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muser \u001b[38;5;241m=\u001b[39m \u001b[43mUserModel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# [classes, B, H, W]\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mannotations \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Golo\\Documents\\Uni\\Bachelorarbeit\\Interactive-DVR\\src\\example\\..\\user_model.py:26\u001b[0m, in \u001b[0;36mUserModel.__init__\u001b[1;34m(self, ground_truth, cfg, brush_sizes)\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mslice_selection \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 26\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInvalid slice selection method. Choose between \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cfg[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvoxel_selection\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvoxel_selection \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid slice selection method. Choose between \"mean\" and \"max\"."
     ]
    }
   ],
   "source": [
    "# we set balance to true. This also effects the dataloader later\n",
    "balance = True\n",
    "#dataset = AEDataset(cfg, modality='segmentation', normalize=True,\n",
    "#                    set=2, augment=False, balance=balance, init='per_class', to_gpu=False)\n",
    "dataset = AEDataset(cfg, modality='segmentation', normalize=True,\n",
    "                    set=2, augment=False, balance=balance, init='three_slices', to_gpu=False)\n",
    "\n",
    "# currently, there are no annotations. We can also enforce this with clear_annotations() at any point\n",
    "dataset.clear_annotation()\n",
    "# get initial annotations\n",
    "annot = dataset.initial_annotation(seed=42)\n",
    "# and update the dataset\n",
    "dataset.update_annotation(annot)\n",
    "print(f\"number of annotations: {dataset.annotations.detach().cpu().sum()}\")\n",
    "\n",
    "# The dataset currently always provides 4 items. Input (the image), target (the input for reconstruction or \n",
    "# the annotations for segmentation), weights that mask out voxels which are not annotated for segmentation \n",
    "# and a brain mask for masking background during reconstruction\n",
    "item = dataset[0]\n",
    "print(item.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f901cd0-8b3b-4cb5-8b32-f89ab55a8595",
   "metadata": {},
   "source": [
    "# Model and Inference\n",
    "\n",
    "The overall pipeline is illustrated in the README."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9e0d19-66c2-46ff-8f8c-bab0943aadba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# At first, we do not have annotations but still need features for the Random Forest. So we pre-train \n",
    "# on a reconstruction task and later re-use the same Encoder (the part of the network that outputs our features),\n",
    "# simply replace the decoder and resume training. \n",
    "\n",
    "# init the model with segmentation decoder. Have a look at the source code for additional guidance. The dataset\n",
    "# updates the config to contain labels. We initialize with one channel per class.\n",
    "model = DualBranchAE(encoder    = 'dual',\n",
    "                     decoder    = 'segmentation',\n",
    "                     in_size    = 145,\n",
    "                     n_classes  = len(cfg['labels']),\n",
    "                     thresholds = 'learned') #.to(cfg['rank'])\n",
    "\n",
    "# example model from one of the experiments\n",
    "#model_path = 'example_dual_xy_0_best.pt'\n",
    "model_path = 'models/Test_best.pt'\n",
    "\n",
    "# load the components\n",
    "checkpoint           = torch.load(model_path)\n",
    "model_state_dict     = checkpoint['model_dict']\n",
    "encoder_state_dict   = {k.replace('encoder.', ''): v for k, v in model_state_dict.items() if 'encoder' in k}\n",
    "\n",
    "# copy encoder weights to model. Decoder weights remain as they are, initialized as random\n",
    "model.encoder.load_state_dict(encoder_state_dict, strict=True)\n",
    "\n",
    "# Define the dataloader. If we use balanced sampling in the dataset, we also need the custom balanced_collate \n",
    "# function in the dataloader. This handles the unusal batching logic.\n",
    "\n",
    "if balance:\n",
    "    loader  = DataLoader(dataset, \n",
    "                         batch_size=cfg['w_batch_size'], \n",
    "                         shuffle=True, \n",
    "                         drop_last=False, \n",
    "                         collate_fn=balanced_collate)\n",
    "else:\n",
    "    loader  = DataLoader(dataset, \n",
    "                         batch_size=16, \n",
    "                         shuffle=True, \n",
    "                         drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c31b2b-2858-4b44-b99a-01a1caa794db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For evaluation, we are interested in the Random Forest (RF) prediction based on\n",
    "# the CNN features. \n",
    "\n",
    "# write checkpoints for stuff that changes the behaviour of the dataset.\n",
    "# E.g. balancing changes the __getitem__ method and thus influences \n",
    "# evaluation. Turn it off and on later if needed.\n",
    "augment_checkpoint = dataset.augment\n",
    "balance_checkpoint = dataset.balance\n",
    "dataset.augment = False\n",
    "dataset.balance = False\n",
    "\n",
    "# define the layer you want the features from. This is usually the encoder output.\n",
    "f_layer = 'encoder'\n",
    "# Init the feature extractor. Have a look at PyTorchs Hook functionality.\n",
    "extractor = FeatureExtractor(model, layers=[f_layer])\n",
    "# Cache all features for a dataset and reformat/move to numpy for random forest stuff\n",
    "hooked_results  = extractor(dataset)\n",
    "features = hooked_results[f_layer]\n",
    "features  = features.permute(0,2,3,1).numpy()\n",
    "# In the utils file are a bunch of evaluation scripts, some are not used anymore.\n",
    "# This one provides F1 scores for the whole dataset based on all ground truth labels\n",
    "# and also the predictions themselve as given by the RF. We need them later to update the annotations with\n",
    "# the user model.\n",
    "\n",
    "# Turn dataset attributes to normal again\n",
    "dataset.augment = augment_checkpoint\n",
    "dataset.balance = balance_checkpoint\n",
    "\n",
    "\n",
    " #Now you can change the model and features to your liking and try again (e.g. via constrastive learning ;)).\n",
    " #The scores from the RF are the signal you need for evaluation, the rest is up to you."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70f0c37",
   "metadata": {},
   "source": [
    "# Uncertainty Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437e0cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(n_annots: list, f1_scores: list):\n",
    "    print(f'Iteration | # Annotations | F1 Score')\n",
    "    print(f'----------|---------------|---------')\n",
    "    for i, (n, f1) in enumerate(zip(n_annots, f1_scores)):\n",
    "        if i in [0, 1, 2, 3, 4, 9, 14, 19, 24, 29, 34, 39, 44, 49, 54]:\n",
    "            print(f'{i+1:>9} | {int(n):>13} | {f1:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7757acc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wir brauchen für die erste Iteration mindestens 1 Annotation damit der RF funktioniert\n",
    "def re_init_dataset():\n",
    "    dataset.clear_annotation()\n",
    "    annot = dataset.initial_annotation(seed=42)\n",
    "    dataset.update_annotation(annot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8516af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(method, n_epochs: int, measures: List[str]):\n",
    "    re_init_dataset()\n",
    "    print(f'Selection using {method}')\n",
    "    #print(f\"number of annotations: {dataset.annotations.detach().cpu().sum()}\")\n",
    "    scores, rf_prediction, unc, unc_pc = evaluate_RF_with_uncertainty(dataset, features, cfg, measures)\n",
    "    print(f\"Average F1 score for RF after initial user interaction:    {scores['Avg_f1_tracts'].item():.4f}\")\n",
    "\n",
    "    n_annots = []\n",
    "    annots = []\n",
    "    f1_scores = []\n",
    "    rf_predictions = []\n",
    "    uncs_pc = []\n",
    "    uncs = []\n",
    "\n",
    "    for i in tqdm(range(n_epochs), desc='User interaction', unit='iteration'):\n",
    "        #print(f\"Iteration {i+1}\")\n",
    "        if method == 'random':\n",
    "            annot = dataset.random_refinement_annotation(prediction=rf_prediction, seed=42)\n",
    "        elif method == 'ground-truth':\n",
    "            annot = dataset.refinement_annotation(prediction=rf_prediction, seed=42)\n",
    "        else:\n",
    "            annot = dataset.uncertainty_refinement_annotation(prediction=rf_prediction, uncertainty_map=unc_pc[method], seed=42)\n",
    "        dataset.update_annotation(annot)\n",
    "        annots.append(dataset.annotations.detach().cpu())\n",
    "        n_annots.append(dataset.annotations.detach().cpu().sum().item())\n",
    "        #print(f\"number of annotations: {dataset.annotations.detach().cpu().sum()}\")\n",
    "        scores, rf_prediction, unc, unc_pc = evaluate_RF_with_uncertainty(dataset, features, cfg, measures)\n",
    "        rf_predictions.append(rf_prediction)\n",
    "        uncs_pc.append(unc_pc)\n",
    "        uncs.append(unc)\n",
    "        f1_scores.append(scores['Avg_f1_tracts'].item())\n",
    "        #print(f\"Average F1 score for RF after additional user interaction: {scores['Avg_f1_tracts'].item():.4f}\")\n",
    "    \n",
    "    print_results(n_annots, f1_scores)\n",
    "    return n_annots, annots, f1_scores, rf_predictions, uncs_pc, uncs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48d9b820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selection using entropy\n",
      "Average F1 score for RF after initial user interaction:    0.2586\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b86c9151e9bd48549643a6c53492ede8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "User interaction:   0%|          | 0/5 [00:00<?, ?iteration/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m ns_e, ans_e, f1s_e, rf_preds_e, uncs_pc_e, uncs_e \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mentropy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeasures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mentropy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[15], line 27\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(method, n_epochs, measures)\u001b[0m\n\u001b[0;32m     25\u001b[0m n_annots\u001b[38;5;241m.\u001b[39mappend(dataset\u001b[38;5;241m.\u001b[39mannotations\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem())\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m#print(f\"number of annotations: {dataset.annotations.detach().cpu().sum()}\")\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m scores, rf_prediction, unc, unc_pc \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_RF_with_uncertainty\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeasures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m rf_predictions\u001b[38;5;241m.\u001b[39mappend(rf_prediction)\n\u001b[0;32m     29\u001b[0m uncs_pc\u001b[38;5;241m.\u001b[39mappend(unc_pc)\n",
      "File \u001b[1;32mc:\\Users\\Golo\\Documents\\Uni\\Bachelorarbeit\\Interactive-DVR\\src\\example\\..\\utils.py:485\u001b[0m, in \u001b[0;36mevaluate_RF_with_uncertainty\u001b[1;34m(dataset, features, cfg, uncertainty_measures)\u001b[0m\n\u001b[0;32m    474\u001b[0m clf \u001b[38;5;241m=\u001b[39m RandomForestClassifier(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,\n\u001b[0;32m    475\u001b[0m                      bootstrap\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    476\u001b[0m                      oob_score\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    481\u001b[0m                      max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    482\u001b[0m                      min_samples_leaf\u001b[38;5;241m=\u001b[39mcfg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin_samples_leaf\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    484\u001b[0m \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[1;32m--> 485\u001b[0m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    486\u001b[0m \u001b[38;5;66;03m# predict labels in test mask\u001b[39;00m\n\u001b[0;32m    487\u001b[0m predicted_prob    \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mpredict_proba(X_test)\n",
      "File \u001b[1;32mc:\\Users\\Golo\\miniconda3\\envs\\BA\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Golo\\miniconda3\\envs\\BA\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:456\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    445\u001b[0m trees \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_estimator(append\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39mrandom_state)\n\u001b[0;32m    447\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[0;32m    448\u001b[0m ]\n\u001b[0;32m    450\u001b[0m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[0;32m    451\u001b[0m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[0;32m    454\u001b[0m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[1;32m--> 456\u001b[0m trees \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mthreads\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    462\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    463\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    464\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    465\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    466\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    467\u001b[0m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    468\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    469\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    470\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    471\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    472\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    473\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    474\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    476\u001b[0m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_\u001b[38;5;241m.\u001b[39mextend(trees)\n",
      "File \u001b[1;32mc:\\Users\\Golo\\miniconda3\\envs\\BA\\Lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Golo\\miniconda3\\envs\\BA\\Lib\\site-packages\\joblib\\parallel.py:1952\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1946\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[0;32m   1947\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[0;32m   1948\u001b[0m \u001b[38;5;66;03m# reach the first `yield` statement. This starts the aynchronous\u001b[39;00m\n\u001b[0;32m   1949\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[0;32m   1950\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1952\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Golo\\miniconda3\\envs\\BA\\Lib\\site-packages\\joblib\\parallel.py:1595\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1592\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m   1594\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[1;32m-> 1595\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[0;32m   1597\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[0;32m   1598\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[0;32m   1599\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[0;32m   1600\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[0;32m   1601\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Golo\\miniconda3\\envs\\BA\\Lib\\site-packages\\joblib\\parallel.py:1707\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1702\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[0;32m   1703\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[0;32m   1704\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m   1705\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[0;32m   1706\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[1;32m-> 1707\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[0;32m   1708\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   1710\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[0;32m   1711\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[0;32m   1712\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ns_e, ans_e, f1s_e, rf_preds_e, uncs_pc_e, uncs_e = train(method='entropy', n_epochs=5, measures=['entropy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ad3342",
   "metadata": {},
   "source": [
    "### Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b72f5cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selection using ground-truth\n",
      "Average F1 score for RF after initial user interaction:    0.2586\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36d7e02e76c74b9aba5f1578317d5177",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "User interaction:   0%|          | 0/20 [00:00<?, ?iteration/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration | # Annotations | F1 Score\n",
      "----------|---------------|---------\n",
      "        1 |          4450 | 0.3434\n",
      "        2 |          5202 | 0.3402\n",
      "        3 |          7165 | 0.4151\n",
      "        4 |          9343 | 0.4378\n",
      "        5 |         11539 | 0.4883\n",
      "       10 |         19009 | 0.5860\n",
      "       15 |         24642 | 0.6287\n",
      "       20 |         29759 | 0.6647\n"
     ]
    }
   ],
   "source": [
    "ns, ans, f1s, rf_preds, uncs_pc, uncs = train(method='ground-truth', n_epochs=20, measures=['ground-truth', 'entropy', 'spatial-distance', 'feature-distance'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f391124d",
   "metadata": {},
   "source": [
    "### Entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d55839",
   "metadata": {},
   "source": [
    "### Spatial Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7cd26406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selection using spatial-distance\n",
      "Average F1 score for RF after initial user interaction:    0.2586\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0eefb6e9acc1435ba958786554c4634e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "User interaction:   0%|          | 0/20 [00:00<?, ?iteration/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration | # Annotations | F1 Score\n",
      "----------|---------------|---------\n",
      "        1 |          2965 | 0.2646\n",
      "        2 |          3238 | 0.2669\n",
      "        3 |          3571 | 0.2732\n",
      "        4 |          3867 | 0.2703\n",
      "        5 |          4201 | 0.2706\n",
      "       10 |          5721 | 0.2804\n",
      "       15 |          7317 | 0.2939\n",
      "       20 |          9118 | 0.2898\n"
     ]
    }
   ],
   "source": [
    "ns_sd, ans_sd, f1s_sd, rf_preds_sd, uncs_pc_sd, uncs_sd = train(method='spatial-distance', n_epochs=20, measures=['spatial-distance'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceee0949",
   "metadata": {},
   "source": [
    "### Feature Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3cac61b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selection using feature-distance\n",
      "Average F1 score for RF after initial user interaction:    0.2586\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac7d512c3b4e4775a782b9a21ab603a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "User interaction:   0%|          | 0/20 [00:00<?, ?iteration/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration | # Annotations | F1 Score\n",
      "----------|---------------|---------\n",
      "        1 |          3183 | 0.2679\n",
      "        2 |          3723 | 0.2648\n",
      "        3 |          4316 | 0.2675\n",
      "        4 |          4903 | 0.2653\n",
      "        5 |          5325 | 0.2676\n",
      "       10 |          8179 | 0.2658\n",
      "       15 |         10922 | 0.2691\n",
      "       20 |         13844 | 0.2615\n"
     ]
    }
   ],
   "source": [
    "ns_fd, ans_fd, f1s_fd, rf_preds_fd, uncs_pc_fd, uncs_fd = train(method='feature-distance', n_epochs=20, measures=['feature-distance'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284b0a90",
   "metadata": {},
   "source": [
    "### Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f63d23b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selection using random\n",
      "Average F1 score for RF after initial user interaction:    0.2586\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c095390985904feab03df93e237d8736",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "User interaction:   0%|          | 0/20 [00:00<?, ?iteration/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration | # Annotations | F1 Score\n",
      "----------|---------------|---------\n",
      "        1 |          2922 | 0.2572\n",
      "        2 |          3202 | 0.2663\n",
      "        3 |          3477 | 0.2734\n",
      "        4 |          3735 | 0.2716\n",
      "        5 |          4020 | 0.2739\n",
      "       10 |          5238 | 0.2747\n",
      "       15 |          6499 | 0.2740\n",
      "       20 |          7845 | 0.2786\n"
     ]
    }
   ],
   "source": [
    "ns_r, ans_r, f1s_r, rf_preds_r, uncs_pc_r, uncs_r = train(method='random', n_epochs=20, measures=['random'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ddadeb70",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, annots in enumerate(ans_e):\n",
    "    if i in (0,1,2,3,4, 9, 14, 19):\n",
    "        torch.save(annots, f'annotations/annots_{i+1}_entropy.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "43857ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, annots in enumerate(ans_sd):\n",
    "    if i in (0,1,2,3,4, 9, 14, 19):\n",
    "        torch.save(annots, f'annotations/annots_{i+1}_sd.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1d0845c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, annots in enumerate(ans_fd):\n",
    "    if i in (0,1,2,3,4, 9, 14, 19):\n",
    "        torch.save(annots, f'annotations/annots_{i+1}_fd.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df06a66",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "cc162e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_maps = [torch.ne(rf_prediction, dataset.label) * 1 for rf_prediction in rf_preds]\n",
    "error_maps_mean = [torch.any(error_map, dim=0) * 1 for error_map in error_maps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5ffbe52b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15243125, 3])\n",
      "torch.Size([15243125])\n",
      "torch.Size([15243125, 1])\n"
     ]
    }
   ],
   "source": [
    "abc = uncs_pc[0]['entropy'].flatten()\n",
    "defg = uncs_pc[0]['spatial-distance'].flatten()\n",
    "hijk = uncs_pc[0]['feature-distance'].flatten()\n",
    "lmno = torch.stack((abc, defg, hijk), dim=1)\n",
    "print(lmno.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7d4c3a17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93aed4c7d42a45cebbbaf5d308a13fa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculation:   0%|          | 0/20 [00:00<?, ?iteration/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Koeffizient für Iteration 1: Entropy: [[6.80838514]], SD: [[0.03420244]], FD: [[5.14872597]]\n",
      "Koeffizient für Iteration 1: Combined: [[ 6.72757369 -0.0340217   0.63251322]]\n",
      "Koeffizient für Iteration 2: Entropy: [[7.02794357]], SD: [[0.03219433]], FD: [[5.32265189]]\n",
      "Koeffizient für Iteration 2: Combined: [[ 6.73033755 -0.03509393  1.2549075 ]]\n",
      "Koeffizient für Iteration 3: Entropy: [[6.6982623]], SD: [[0.02620928]], FD: [[5.05152733]]\n",
      "Koeffizient für Iteration 3: Combined: [[ 6.29420073 -0.0529336   1.9025076 ]]\n",
      "Koeffizient für Iteration 4: Entropy: [[6.8116268]], SD: [[0.02158613]], FD: [[4.87395059]]\n",
      "Koeffizient für Iteration 4: Combined: [[ 6.59178342 -0.06249266  1.17257243]]\n",
      "Koeffizient für Iteration 5: Entropy: [[7.19238669]], SD: [[0.01998846]], FD: [[4.75844355]]\n",
      "Koeffizient für Iteration 5: Combined: [[ 7.08846542 -0.05720406  0.35012152]]\n",
      "Koeffizient für Iteration 6: Entropy: [[7.31138677]], SD: [[0.02119565]], FD: [[4.94982176]]\n",
      "Koeffizient für Iteration 6: Combined: [[ 7.19909338 -0.05252118  0.28792025]]\n",
      "Koeffizient für Iteration 7: Entropy: [[7.46501753]], SD: [[0.02088356]], FD: [[4.98891402]]\n",
      "Koeffizient für Iteration 7: Combined: [[ 7.32527822 -0.05210517  0.32009922]]\n",
      "Koeffizient für Iteration 8: Entropy: [[7.4728109]], SD: [[0.01655445]], FD: [[4.91746136]]\n",
      "Koeffizient für Iteration 8: Combined: [[ 7.25948023 -0.07076499  0.66780789]]\n",
      "Koeffizient für Iteration 9: Entropy: [[7.65695715]], SD: [[0.01807795]], FD: [[5.01641968]]\n",
      "Koeffizient für Iteration 9: Combined: [[ 7.44588136 -0.06067749  0.63144986]]\n",
      "Koeffizient für Iteration 10: Entropy: [[7.88620087]], SD: [[0.0149105]], FD: [[5.01443593]]\n",
      "Koeffizient für Iteration 10: Combined: [[ 7.63706166 -0.07136907  0.64764366]]\n",
      "Koeffizient für Iteration 11: Entropy: [[7.80623337]], SD: [[0.01361651]], FD: [[5.01710035]]\n",
      "Koeffizient für Iteration 11: Combined: [[ 7.55980865 -0.07544111  0.72586051]]\n",
      "Koeffizient für Iteration 12: Entropy: [[8.16946721]], SD: [[0.01329917]], FD: [[5.02519462]]\n",
      "Koeffizient für Iteration 12: Combined: [[ 7.86130355 -0.06921299  0.66288778]]\n",
      "Koeffizient für Iteration 13: Entropy: [[8.31745989]], SD: [[0.01391267]], FD: [[4.99480433]]\n",
      "Koeffizient für Iteration 13: Combined: [[ 8.10190511 -0.06081465  0.14810018]]\n",
      "Koeffizient für Iteration 14: Entropy: [[8.41426768]], SD: [[0.00948413]], FD: [[4.77357729]]\n",
      "Koeffizient für Iteration 14: Combined: [[ 8.16773365 -0.08207386  0.01620754]]\n",
      "Koeffizient für Iteration 15: Entropy: [[8.46227659]], SD: [[0.00888615]], FD: [[4.79644047]]\n",
      "Koeffizient für Iteration 15: Combined: [[ 8.1680069  -0.08400236  0.18326467]]\n",
      "Koeffizient für Iteration 16: Entropy: [[8.48307514]], SD: [[0.00942583]], FD: [[4.81521878]]\n",
      "Koeffizient für Iteration 16: Combined: [[ 8.22003659 -0.07857311  0.06067939]]\n",
      "Koeffizient für Iteration 17: Entropy: [[8.46032853]], SD: [[0.00933179]], FD: [[4.81248473]]\n",
      "Koeffizient für Iteration 17: Combined: [[ 8.17852393 -0.07791324  0.10570233]]\n",
      "Koeffizient für Iteration 18: Entropy: [[8.41374414]], SD: [[0.00800668]], FD: [[4.84997114]]\n",
      "Koeffizient für Iteration 18: Combined: [[ 8.11880232 -0.08526206  0.20948633]]\n",
      "Koeffizient für Iteration 19: Entropy: [[8.42593934]], SD: [[0.00739057]], FD: [[4.83043808]]\n",
      "Koeffizient für Iteration 19: Combined: [[ 8.12384395 -0.08665315  0.13084176]]\n",
      "Koeffizient für Iteration 20: Entropy: [[8.41835179]], SD: [[0.00618593]], FD: [[4.83350501]]\n",
      "Koeffizient für Iteration 20: Combined: [[ 8.07763439 -0.08778883  0.23979653]]\n"
     ]
    }
   ],
   "source": [
    "# Create and fit the logistic regression model\n",
    "for i, (unc_map, error_map) in enumerate(tqdm(zip(uncs_pc, error_maps),total=len(uncs_pc), desc='Calculation', unit='iteration')):\n",
    "    unc_map_e = unc_map['entropy'].flatten()\n",
    "    unc_map_sd = unc_map['spatial-distance'].flatten()\n",
    "    unc_map_fd = unc_map['feature-distance'].flatten()\n",
    "    logreg_e = LogisticRegression(random_state=0, n_jobs=-1)\n",
    "    logreg_e.fit(unc_map_e.reshape(-1, 1), error_map.flatten())\n",
    "    logreg_sd = LogisticRegression(random_state=0, n_jobs=-1)\n",
    "    logreg_sd.fit(unc_map_sd.reshape(-1, 1), error_map.flatten())\n",
    "    logreg_fd = LogisticRegression(random_state=0, n_jobs=-1)\n",
    "    logreg_fd.fit(unc_map_fd.reshape(-1, 1), error_map.flatten())\n",
    "    print(f\"Koeffizient für Iteration {i+1}: Entropy: {logreg_e.coef_}, SD: {logreg_sd.coef_}, FD: {logreg_fd.coef_}\")\n",
    "    logreg_c = LogisticRegression(random_state=0, n_jobs=-1)\n",
    "    logreg_c.fit(torch.stack((unc_map_e, unc_map_sd, unc_map_fd), dim=1), error_map.flatten())\n",
    "    print(f\"Koeffizient für Iteration {i+1}: Combined: {logreg_c.coef_}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
