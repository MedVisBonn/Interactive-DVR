{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f5b8d26-e301-49fd-b2bb-a185310027f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Golo\\miniconda3\\envs\\BA\\Lib\\site-packages\\torch\\utils\\_contextlib.py:125: UserWarning: Decorating classes is deprecated and will be disabled in future versions. You should only decorate functions or methods. To preserve the current behavior of class decoration, you can directly decorate the `__init__` method and nothing else.\n",
      "  warnings.warn(\"Decorating classes is deprecated and will be disabled in \"\n"
     ]
    }
   ],
   "source": [
    "#import os, sys\n",
    "#from time import time\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Adam\n",
    "#from torch.cuda.amp import GradScaler, autocast\n",
    "#from torch.utils.data._utils.collate import default_collate\n",
    "#import copy\n",
    "#from time import time\n",
    "#import wandb\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Tuple\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from dataset import AEDataset\n",
    "from trainer import Trainer, WeakSupervisionTrainer\n",
    "from model import DualBranchAE\n",
    "from utils import *\n",
    "from losses import MSELoss\n",
    "from pretrainer import PreTrainer\n",
    "from torchmetrics.classification import BinaryROC\n",
    "from scipy import ndimage\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cc02d84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# auto reload changes in .py files\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "211305c3-326d-4c47-bbec-5087737b3390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %cd example/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb22710-307a-4146-8bdd-57bba48aad1e",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "We currently work on the HPC data and within this, we built two different segmentation tasks. Further details are in the paper https://cg.cs.uni-bonn.de/backend/v1/files/publications/torayev-vcbm2020.pdf. Neither the whole dataset nor the model are in this repo. We will set you up once you started your work and give your access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c199b3f-5e9b-4d46-acdb-3770417afc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# which tasks are used is handled by \"set\". 1 is a binary task for debugging, 2 is multi-class \n",
    "# and so is 3 but with asymmetric classes w.r.t. the saggital plane (harder). Details for \n",
    "# set 2 and 3 are in the paper.\n",
    "# 'modality' handles the target provided by __getitem__. Options are reconstruction and segmentation.\n",
    "# When segmentation is selected, the labels are taken from the annotations attribute. This is also where\n",
    "# the user-model interacts with the dataset. Ground truth masks are in the label attribute. All other parameters are\n",
    "# from past experiments and alter the behaviour. This project has been around for a while, so some are not used anymore.\n",
    "\n",
    "# normalize is usually set to true. Simply normalizes the input. Augment is legacy, we didn't have much success\n",
    "# with data augmentation. balance takes care of data balancing during a batch. Some classes are under-\n",
    "# represented so we show them to the model more often. It helps quite a bit during training so consider \n",
    "# integrating it. We can talk about how this is done in detail once you start. init defines how the user-model behaves. \n",
    "# We considered different behaviours w.r.t. to annotation style and quantity and such. \n",
    "# To_gpu moves ALL data to GPU. Since we only work on a single volume (i.e. couple hundred slices) \n",
    "# we move everything to GPU and avoid latency in dataloading. Takes a hefty chunk out of the VRAM though \n",
    "# but makes things faster.\n",
    "\n",
    "# Feel free to re-write anything you want. This is partly dated code that could use a re-write anyways.\n",
    "\n",
    "# Example:\n",
    "# make a config first. This handles globals and is used through-out the script. Many things that were tried in\n",
    "# experiments later have not yet made it into the config, but most have.\n",
    "\n",
    "cfg = {\n",
    "    # CONFIG\n",
    "    'name': 'location-unsupervised',\n",
    "    'project': 'IDVR-localization_pretrain',\n",
    "    'log': False,\n",
    "    'rank': 0,\n",
    "    \n",
    "    # DATA\n",
    "    'data_dir': '../../../data/784565/Diffusion/',\n",
    "    'data_path': '../../../data/784565/Diffusion/data.nii',\n",
    "    'active_mask_path': '../../../data/784565/Diffusion/nodif_brain_mask.nii.gz',\n",
    "\n",
    "    #'data_dir': '../../../data/771354/Diffusion/',\n",
    "    #'data_path': '../../../data/771354/Diffusion/data.nii.gz',\n",
    "    #'active_mask_path': '../../../data/771354/Diffusion/nodif_brain_mask.nii.gz',\n",
    "    \n",
    "    # SELF SUPERVISED PRE-TRAINING\n",
    "    's_n_epochs': 20,\n",
    "    's_batch_size': 16, # default: 8\n",
    "    's_lr': 5e-4, #1e-4, 1e-5        \n",
    "    \n",
    "    # TRAINING WITH WEAK SUPERVISION\n",
    "    'p_n_epochs': 100,\n",
    "    'w_n_epochs': 10,\n",
    "    'w_batch_size': 2,\n",
    "    'w_lr': 5e-4,    #5e-5 \n",
    "    'w_eval_freq': 100,\n",
    "    \n",
    "    # RANDOM FOREST\n",
    "    'min_samples_leaf': 8,\n",
    "    \n",
    "    # USER MODEL\n",
    "    'init_voxels': 200,\n",
    "    'refinement_voxels': 200,\n",
    "    'num_interactions': 10,\n",
    "    'brush' : False,\n",
    "    'slice_selection' : 'mean',\n",
    "    'voxel_selection' : 'max',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66666ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of annotations: 1072.0\n",
      "dict_keys(['input', 'target', 'weight', 'mask'])\n"
     ]
    }
   ],
   "source": [
    "# we set balance to true. This also effects the dataloader later\n",
    "balance = False\n",
    "# dataset = AEDataset(cfg, modality='segmentation', normalize=True,\n",
    "                    # set=2, augment=False, balance=balance, init='per_class', to_gpu=False)\n",
    "dataset = AEDataset(cfg, modality='segmentation', normalize=True,\n",
    "                    set=2, augment=False, balance=balance, init='per_class', to_gpu=False)\n",
    "# dataset = AEDataset(cfg, modality='segmentation', normalize=True,\n",
    "                    # set=2, augment=False, balance=balance, init='three_slices', to_gpu=False)\n",
    "\n",
    "# currently, there are no annotations. We can also enforce this with clear_annotations() at any point\n",
    "dataset.clear_annotation()\n",
    "# get initial annotations\n",
    "annot = dataset.initial_annotation(seed=42)\n",
    "# and update the dataset\n",
    "dataset.update_annotation(annot)\n",
    "print(f\"number of annotations: {dataset.annotations.detach().cpu().sum()}\")\n",
    "\n",
    "# The dataset currently always provides 4 items. Input (the image), target (the input for reconstruction or \n",
    "# the annotations for segmentation), weights that mask out voxels which are not annotated for segmentation \n",
    "# and a brain mask for masking background during reconstruction\n",
    "item = dataset[0]\n",
    "print(item.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2e1a1bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2837632.)\n",
      "tensor(44468.)\n",
      "tensor(33859.)\n",
      "tensor(960.)\n",
      "tensor(186667.)\n"
     ]
    }
   ],
   "source": [
    "for i in range(dataset.label.shape[0]):\n",
    "    print(dataset.label[i].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0d20e7ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 145, 145, 145])\n"
     ]
    }
   ],
   "source": [
    "print(dataset.label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2be1b371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1072.)\n",
      "(tensor([0., 1., 2.]), tensor([3047625,     928,      72]))\n"
     ]
    }
   ],
   "source": [
    "print(dataset.annotations.sum())\n",
    "print(dataset.annotations.sum(dim=0).unique(return_counts=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f901cd0-8b3b-4cb5-8b32-f89ab55a8595",
   "metadata": {},
   "source": [
    "# Model and Inference\n",
    "\n",
    "The overall pipeline is illustrated in the README."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f9e0d19-66c2-46ff-8f8c-bab0943aadba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# At first, we do not have annotations but still need features for the Random Forest. So we pre-train \n",
    "# on a reconstruction task and later re-use the same Encoder (the part of the network that outputs our features),\n",
    "# simply replace the decoder and resume training. \n",
    "\n",
    "# init the model with segmentation decoder. Have a look at the source code for additional guidance. The dataset\n",
    "# updates the config to contain labels. We initialize with one channel per class.\n",
    "model = DualBranchAE(encoder    = 'dual',\n",
    "                     decoder    = 'segmentation',\n",
    "                     in_size    = 145,\n",
    "                     n_classes  = len(cfg['labels']),\n",
    "                     thresholds = 'learned', \n",
    "                     dropout = False, \n",
    "                     dropout_rate=0.2) #.to(cfg['rank'])\n",
    "\n",
    "# example model from one of the experiments\n",
    "#model_path = 'example_dual_xy_0_best.pt'\n",
    "#model_path = 'models/hope_best.pt'\n",
    "model_path = 'models/Test_best.pt'\n",
    "#model_path = 'models/Set3_best.pt'\n",
    "#model_path = 'models/Dropout-0.5_best.pt'\n",
    "#model_path = 'models/Dropout-0.2_best.pt'\n",
    "#model_path = 'models/Dropout-0.05_best.pt'\n",
    "\n",
    "# load the components\n",
    "checkpoint           = torch.load(model_path)\n",
    "model_state_dict     = checkpoint['model_dict']\n",
    "encoder_state_dict   = {k.replace('encoder.', ''): v for k, v in model_state_dict.items() if 'encoder' in k}\n",
    "# print(model_state_dict.keys())\n",
    "\n",
    "# copy encoder weights to model. Decoder weights remain as they are, initialized as random\n",
    "model.encoder.load_state_dict(encoder_state_dict, strict=True)\n",
    "\n",
    "# Define the dataloader. If we use balanced sampling in the dataset, we also need the custom balanced_collate \n",
    "# function in the dataloader. This handles the unusal batching logic.\n",
    "\n",
    "if balance:\n",
    "    loader  = DataLoader(dataset, \n",
    "                         batch_size=cfg['w_batch_size'], \n",
    "                         shuffle=True, \n",
    "                         drop_last=False, \n",
    "                         collate_fn=balanced_collate)\n",
    "else:\n",
    "    loader  = DataLoader(dataset, \n",
    "                         batch_size=16, \n",
    "                         shuffle=True, \n",
    "                         drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32c31b2b-2858-4b44-b99a-01a1caa794db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For evaluation, we are interested in the Random Forest (RF) prediction based on\n",
    "# the CNN features. \n",
    "\n",
    "# write checkpoints for stuff that changes the behaviour of the dataset.\n",
    "# E.g. balancing changes the __getitem__ method and thus influences \n",
    "# evaluation. Turn it off and on later if needed.\n",
    "augment_checkpoint = dataset.augment\n",
    "balance_checkpoint = dataset.balance\n",
    "dataset.augment = False\n",
    "dataset.balance = False\n",
    "\n",
    "# define the layer you want the features from. This is usually the encoder output.\n",
    "f_layer = 'encoder'\n",
    "# Init the feature extractor. Have a look at PyTorchs Hook functionality.\n",
    "extractor = FeatureExtractor(model, layers=[f_layer])\n",
    "\n",
    "# Cache all features for a dataset and reformat/move to numpy for random forest stuff\n",
    "hooked_results  = extractor(dataset)\n",
    "features = hooked_results[f_layer]\n",
    "features  = features.permute(0,2,3,1).numpy()\n",
    "# In the utils file are a bunch of evaluation scripts, some are not used anymore.\n",
    "# This one provides F1 scores for the whole dataset based on all ground truth labels\n",
    "# and also the predictions themselve as given by the RF. We need them later to update the annotations with\n",
    "# the user model.\n",
    "\n",
    "# Turn dataset attributes to normal again\n",
    "dataset.augment = augment_checkpoint\n",
    "dataset.balance = balance_checkpoint\n",
    "\n",
    " #Now you can change the model and features to your liking and try again (e.g. via constrastive learning ;)).\n",
    " #The scores from the RF are the signal you need for evaluation, the rest is up to you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d39721f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27598205\n"
     ]
    }
   ],
   "source": [
    "print(features[0,10,10,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b81617b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27598205\n"
     ]
    }
   ],
   "source": [
    "print(features[0,10,10,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f11a4039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-6.903641 22.450981\n"
     ]
    }
   ],
   "source": [
    "print(features.min(), features.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96eff01a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([   960.,  32601.,  36731., 164087., 557203.]), tensor([1, 1, 1, 1, 1]))\n",
      "(tensor([   960.,  32601.,  36731., 164087., 557203.]), tensor([1, 1, 1, 1, 1]))\n",
      "(tensor([1., 2., 3.]), tensor([696485,  47469,     53]))\n",
      "(tensor([0., 1., 2., 3.]), tensor([557203, 139282,  47469,     53]))\n"
     ]
    }
   ],
   "source": [
    "x = dataset.label.permute(1,2,3,0)\n",
    "print(dataset.label[:, dataset.brain_mask].sum(dim=1).unique(return_counts=True))\n",
    "print(x[dataset.brain_mask].sum(dim=0).unique(return_counts=True))\n",
    "print(x[dataset.brain_mask].sum(dim=1).unique(return_counts=True))\n",
    "print(x[dataset.brain_mask][:, 1:].sum(dim=1).unique(return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66ca8f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([744007, 5])\n",
      "(tensor([0., 1.]), tensor([186804, 557203]))\n"
     ]
    }
   ],
   "source": [
    "print(x[dataset.brain_mask].shape)\n",
    "print(x[dataset.brain_mask][:, :1].sum(dim=1).unique(return_counts=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70f0c37",
   "metadata": {},
   "source": [
    "# Uncertainty Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "437e0cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(n_annots: list, n_voxel:list, f1_scores: list):\n",
    "    print(f'Iteration | # Annotations | # Annotierte Voxel |F1 Score')\n",
    "    print(f'----------|---------------|--------------------|--------')\n",
    "    for i, (n, v, f1) in enumerate(zip(n_annots, n_voxel, f1_scores)):\n",
    "        if i in [0, 1, 2, 3, 4, 9, 14, 19, 24, 29, 34, 39, 44, 49, 54]:\n",
    "            print(f'{i+1:>9} | {int(n):>13} | {int(v):>18} | {f1:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7757acc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wir brauchen für die erste Iteration mindestens 1 Annotation damit der RF funktioniert\n",
    "def re_init_dataset():\n",
    "    dataset.clear_annotation()\n",
    "    annot = dataset.initial_annotation(seed=42)\n",
    "    dataset.update_annotation(annot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a8516af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(method: str, n_epochs: int, measures: List[str]):\n",
    "    re_init_dataset()\n",
    "    print(f'Selection using {method}')\n",
    "    #print(f\"number of annotations: {dataset.annotations.detach().cpu().sum()}\")\n",
    "    scores, rf_prediction, unc, unc_pc = evaluate_RF(dataset, features, cfg, measures)\n",
    "    #scores, rf_prediction, unc, unc_pc = evaluate_RF_with_uncertainty(dataset, features, cfg, measures)\n",
    "    #scores, rf_prediction = evaluate_RF(dataset, features, cfg)\n",
    "    print(f\"Number of initial annotations: {dataset.annotations.detach().cpu().sum()}\")\n",
    "    #print(dataset.annotations.sum(dim=(1,2,3)).unique(return_counts=True))\n",
    "    print(f'Number of annotated Voxels: {dataset.annotations.any(dim=0).sum()}')\n",
    "    print(f\"Average F1 score for RF after initial user interaction:    {scores['Avg_f1_tracts'].item():.3f}\")\n",
    "    print()\n",
    "    n_annots = []\n",
    "    annots = []\n",
    "    f1_scores = []\n",
    "    rf_predictions = []\n",
    "    uncs_pc = []\n",
    "    uncs = []\n",
    "    annotated_voxels = []\n",
    "\n",
    "\n",
    "    uncs_pc.append(unc_pc)\n",
    "\n",
    "\n",
    "    for i in tqdm(range(n_epochs), desc='User interaction', unit='iteration'):\n",
    "        #print(f\"Iteration {i+1}\")\n",
    "        if method == 'random':\n",
    "            annot = dataset.refinement_annotation(prediction=rf_prediction, random=True, seed=42)\n",
    "        elif method == 'totaly-random':\n",
    "            annot = dataset.refinement_annotation(prediction=rf_prediction, totaly_random = True, seed=42)\n",
    "        elif method == 'ground-truth':\n",
    "            annot = dataset.refinement_annotation(prediction=rf_prediction, seed=42)\n",
    "        else:\n",
    "            annot = dataset.refinement_annotation(prediction=rf_prediction, uncertainty_map=unc_pc[method], seed=42)\n",
    "            #annot = dataset.uncertainty_refinement_annotation(prediction=rf_prediction, uncertainty_map=unc_pc[method], seed=42)\n",
    "\n",
    "        dataset.update_annotation(annot)\n",
    "\n",
    "        \n",
    "        annots.append(dataset.annotations.detach().cpu())\n",
    "        n_annots.append(dataset.annotations.detach().cpu().sum().item())\n",
    "        annotated_voxels.append(dataset.annotations.any(dim=0).sum().item())\n",
    "        #print(f\"number of annotations: {dataset.annotations.detach().cpu().sum()}\")\n",
    "        scores, rf_prediction, unc, unc_pc = evaluate_RF(dataset, features, cfg, measures)\n",
    "\n",
    "        #scores, rf_prediction, unc, unc_pc = evaluate_RF_with_uncertainty(dataset, features, cfg, measures)\n",
    "        #scores, rf_prediction = evaluate_RF(dataset, features, cfg)\n",
    "        rf_predictions.append(rf_prediction)\n",
    "        uncs_pc.append(unc_pc)\n",
    "        uncs.append(unc)\n",
    "        #print(scores)\n",
    "        #if i in [0, 1, 2, 3, 4, 9, 14, 19, 24, 29, 34, 39, 44, 49, 54]:\n",
    "        #    print(torch.any(dataset.annotations, dim=0).sum().item())\n",
    "        \n",
    "        if i == 9:\n",
    "            \n",
    "            \n",
    "            if dataset.set == 2:\n",
    "                print(f'Durschnitt | Andere |  CG  |  CST  |  FX  | CC')\n",
    "                print(f'-----------|--------|------|-------|------|---')\n",
    "                print(f\"{scores['Avg_f1_tracts'].item():>10.2f} | {scores['Other_f1']:>6.2f} | {scores['CG_f1']:>3.2f} | {scores['CST_f1']:>5.2f} | {scores['FX_f1']:>2.2f} | {scores['CC_f1']:>2.2f}\")\n",
    "                \n",
    "                print()\n",
    "                print()\n",
    "\n",
    "                print(f'Gesamt | Andere |  CG  |  CST  |   FX   | CC')\n",
    "                print(f'-------|--------|--------|---------|--------|---')\n",
    "                x = dataset.annotations.sum(dim=(1,2,3))\n",
    "                print(f\"{dataset.annotations.any(dim=0).sum().item():>6} | {x[0].item()} | {x[1].item():>4} | {x[2].item():>5} | {x[3].item()} | {x[4].item()}\")\n",
    "\n",
    "            elif dataset.set == 3:\n",
    "                print(f'Durschnitt | Andere | IFO-l | IFO-r |  ILF-l | ILF-r | SLF-l | SLF-r ')\n",
    "                print(f\"-----------|--------|-------|-------|--------|-------|-------|--------\")\n",
    "                print(f\"{scores['Avg_f1_tracts'].item():>10.2f} | {scores['Other_f1']:>6.2f} | {scores['IFO_left_f1']:>5.2f} | {scores['IFO_right_f1']:>5.2f} | {scores['ILF_left_f1']:>6.2f} | {scores['ILF_right_f1']:>5.2f} | {scores['SLF_left_f1']:>5.2f} | {scores['SLF_right_f1']:>5.2f}\")\n",
    "\n",
    "                print()\n",
    "                print()\n",
    "\n",
    "                print(f'Gesamt | Andere | IFO-l | IFO-r | ILF-l | ILF-r | SLF-l | SLF-r ')\n",
    "                print(f'-------|--------|-------|-------|-------|-------|-------|-------')\n",
    "                x = dataset.annotations.sum(dim=(1,2,3))\n",
    "                print(f\"{dataset.annotations.any(dim=0).sum().item():>6} | {x[0].item()} | {x[1].item()} | {x[2].item()} | {x[3].item()} | {x[4].item()} | {x[5].item()} | {x[6].item()}\")\n",
    "\n",
    "\n",
    "            print()\n",
    "            print()\n",
    "        \n",
    "\n",
    "\n",
    "        f1_scores.append(scores['Avg_f1_tracts'].item())\n",
    "\n",
    "        #print(f\"Average F1 score for RF after additional user interaction: {scores['Avg_f1_tracts'].item():.4f}\")\n",
    "    \n",
    "    print_results(n_annots, annotated_voxels, f1_scores)\n",
    "    return n_annots, annots, f1_scores, rf_predictions, uncs_pc, uncs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f391124d",
   "metadata": {},
   "source": [
    "### Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "48d9b820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selection using entropy\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (5, 364) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m ns_e, ans_e, f1s_e, rf_preds_e, uncs_pc_e, uncs_e \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mentropy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeasures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mentropy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[18], line 5\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(method, n_epochs, measures)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSelection using \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmethod\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m#print(f\"number of annotations: {dataset.annotations.detach().cpu().sum()}\")\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m scores, rf_prediction, unc, unc_pc \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_RF\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeasures\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m#scores, rf_prediction, unc, unc_pc = evaluate_RF_with_uncertainty(dataset, features, cfg, measures)\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m#scores, rf_prediction = evaluate_RF(dataset, features, cfg)\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of initial annotations: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset\u001b[38;5;241m.\u001b[39mannotations\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32md:\\Dokumente\\Uni\\Bachelor\\Bachelorarbeit\\Interactive-DVR\\src\\example\\..\\utils.py:561\u001b[0m, in \u001b[0;36mevaluate_RF\u001b[1;34m(dataset, features, cfg, uncertainty_measures, tta)\u001b[0m\n\u001b[0;32m    549\u001b[0m clf \u001b[38;5;241m=\u001b[39m RandomForestClassifier(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,\n\u001b[0;32m    550\u001b[0m                      bootstrap\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    551\u001b[0m                      oob_score\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    556\u001b[0m                      max_depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    557\u001b[0m                      min_samples_leaf\u001b[38;5;241m=\u001b[39mcfg[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin_samples_leaf\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    559\u001b[0m \u001b[38;5;66;03m# Train\u001b[39;00m\n\u001b[0;32m    560\u001b[0m \u001b[38;5;66;03m#clf.fit(list(X_train), Y_train)\u001b[39;00m\n\u001b[1;32m--> 561\u001b[0m \u001b[43mclf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    562\u001b[0m \u001b[38;5;66;03m# predict labels in test mask\u001b[39;00m\n\u001b[0;32m    563\u001b[0m predicted_prob    \u001b[38;5;241m=\u001b[39m clf\u001b[38;5;241m.\u001b[39mpredict_proba(X_test)\n",
      "File \u001b[1;32mc:\\Users\\Golo\\miniconda3\\envs\\BA\\Lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Golo\\miniconda3\\envs\\BA\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:500\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    496\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_oob_score_and_attributes(\n\u001b[0;32m    497\u001b[0m             X, y, scoring_function\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moob_score\n\u001b[0;32m    498\u001b[0m         )\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 500\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_oob_score_and_attributes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[38;5;66;03m# Decapsulate classes_ attributes\u001b[39;00m\n\u001b[0;32m    503\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclasses_\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_outputs_ \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Golo\\miniconda3\\envs\\BA\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:736\u001b[0m, in \u001b[0;36mForestClassifier._set_oob_score_and_attributes\u001b[1;34m(self, X, y, scoring_function)\u001b[0m\n\u001b[0;32m    724\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_set_oob_score_and_attributes\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y, scoring_function\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    725\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute and set the OOB score and attributes.\u001b[39;00m\n\u001b[0;32m    726\u001b[0m \n\u001b[0;32m    727\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    734\u001b[0m \u001b[38;5;124;03m        Scoring function for OOB score. Defaults to `accuracy_score`.\u001b[39;00m\n\u001b[0;32m    735\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 736\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moob_decision_function_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_oob_predictions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    737\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moob_decision_function_\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    738\u001b[0m         \u001b[38;5;66;03m# drop the n_outputs axis if there is a single output\u001b[39;00m\n\u001b[0;32m    739\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moob_decision_function_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moob_decision_function_\u001b[38;5;241m.\u001b[39msqueeze(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Golo\\miniconda3\\envs\\BA\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:572\u001b[0m, in \u001b[0;36mBaseForest._compute_oob_predictions\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    565\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m estimator \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimators_:\n\u001b[0;32m    566\u001b[0m     unsampled_indices \u001b[38;5;241m=\u001b[39m _generate_unsampled_indices(\n\u001b[0;32m    567\u001b[0m         estimator\u001b[38;5;241m.\u001b[39mrandom_state,\n\u001b[0;32m    568\u001b[0m         n_samples,\n\u001b[0;32m    569\u001b[0m         n_samples_bootstrap,\n\u001b[0;32m    570\u001b[0m     )\n\u001b[1;32m--> 572\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_oob_predictions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43munsampled_indices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    573\u001b[0m     oob_pred[unsampled_indices, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m y_pred\n\u001b[0;32m    574\u001b[0m     n_oob_pred[unsampled_indices, :] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Golo\\miniconda3\\envs\\BA\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:713\u001b[0m, in \u001b[0;36mForestClassifier._get_oob_predictions\u001b[1;34m(tree, X)\u001b[0m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute the OOB predictions for an individual tree.\u001b[39;00m\n\u001b[0;32m    699\u001b[0m \n\u001b[0;32m    700\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    710\u001b[0m \u001b[38;5;124;03m    The OOB associated predictions.\u001b[39;00m\n\u001b[0;32m    711\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    712\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m tree\u001b[38;5;241m.\u001b[39mpredict_proba(X, check_input\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m--> 713\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    714\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_pred\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m    715\u001b[0m     \u001b[38;5;66;03m# binary and multiclass\u001b[39;00m\n\u001b[0;32m    716\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m y_pred[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, np\u001b[38;5;241m.\u001b[39mnewaxis]\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (5, 364) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "ns_e, ans_e, f1s_e, rf_preds_e, uncs_pc_e, uncs_e = train(method='entropy', n_epochs=2, measures=['entropy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d55839",
   "metadata": {},
   "source": [
    "### Spatial Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "7cd26406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selection using spatial-distance\n",
      "Number of initial annotations: 1475.0\n",
      "Number of annotated Voxels: 1384\n",
      "Average F1 score for RF after initial user interaction:    0.467\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "626b7a03afaa4d55858c9a2ad7ac2bcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "User interaction:   0%|          | 0/10 [00:00<?, ?iteration/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Durschnitt | Andere | IFO-l | IFO-r |  ILF-l | ILF-r | SLF-l | SLF-r \n",
      "-----------|--------|-------|-------|--------|-------|-------|--------\n",
      "      0.62 |   0.85 |  0.62 |  0.67 |   0.51 |  0.59 |  0.64 |  0.72\n",
      "\n",
      "\n",
      "Gesamt | Andere | IFO-l | IFO-r | ILF-l | ILF-r | SLF-l | SLF-r \n",
      "-------|--------|-------|-------|-------|-------|-------|-------\n",
      " 12731 | 9559.0 | 697.0 | 794.0 | 251.0 | 306.0 | 625.0 | 1073.0\n",
      "\n",
      "\n",
      "Iteration | # Annotations | # Annotierte Voxel |F1 Score\n",
      "----------|---------------|--------------------|--------\n",
      "        1 |          2523 |               2383 | 0.503\n",
      "        2 |          3768 |               3580 | 0.534\n",
      "        3 |          4795 |               4575 | 0.553\n",
      "        4 |          5839 |               5573 | 0.565\n",
      "        5 |          7080 |               6768 | 0.577\n",
      "       10 |         13305 |              12731 | 0.624\n"
     ]
    }
   ],
   "source": [
    "ns_sd, ans_sd, f1s_sd, rf_preds_sd, uncs_pc_sd, uncs_sd = train(method='spatial-distance', n_epochs=10, measures=['spatial-distance'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceee0949",
   "metadata": {},
   "source": [
    "### Feature Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "85e8eee3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selection using feature-distance\n",
      "Number of initial annotations: 1475.0\n",
      "Number of annotated Voxels: 1384\n",
      "Average F1 score for RF after initial user interaction:    0.467\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2321fd081a3748868441b1abdbf3d2d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "User interaction:   0%|          | 0/10 [00:00<?, ?iteration/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Durschnitt | Andere | IFO-l | IFO-r |  ILF-l | ILF-r | SLF-l | SLF-r \n",
      "-----------|--------|-------|-------|--------|-------|-------|--------\n",
      "      0.58 |   0.72 |  0.64 |  0.63 |   0.57 |  0.53 |  0.48 |  0.61\n",
      "\n",
      "\n",
      "Gesamt | Andere | IFO-l | IFO-r | ILF-l | ILF-r | SLF-l | SLF-r \n",
      "-------|--------|-------|-------|-------|-------|-------|-------\n",
      " 13551 | 10467.0 | 1087.0 | 1120.0 | 247.0 | 168.0 | 357.0 | 782.0\n",
      "\n",
      "\n",
      "Iteration | # Annotations | # Annotierte Voxel |F1 Score\n",
      "----------|---------------|--------------------|--------\n",
      "        1 |          2800 |               2659 | 0.529\n",
      "        2 |          4221 |               4024 | 0.538\n",
      "        3 |          5555 |               5293 | 0.536\n",
      "        4 |          6750 |               6402 | 0.547\n",
      "        5 |          8065 |               7654 | 0.547\n",
      "       10 |         14228 |              13551 | 0.577\n"
     ]
    }
   ],
   "source": [
    "ns_fd, ans_fd, f1s_fd, rf_preds_fd, uncs_pc_fd, uncs_fd = train(method='feature-distance', n_epochs=10, measures=['feature-distance'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ad3342",
   "metadata": {},
   "source": [
    "### Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "b72f5cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selection using ground-truth\n",
      "Number of initial annotations: 1475.0\n",
      "Number of annotated Voxels: 1384\n",
      "Average F1 score for RF after initial user interaction:    0.467\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a5453b5dc3647098ffe353db126c1bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "User interaction:   0%|          | 0/10 [00:00<?, ?iteration/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Durschnitt | Andere | IFO-l | IFO-r |  ILF-l | ILF-r | SLF-l | SLF-r \n",
      "-----------|--------|-------|-------|--------|-------|-------|--------\n",
      "      0.75 |   0.86 |  0.75 |  0.78 |   0.74 |  0.73 |  0.73 |  0.80\n",
      "\n",
      "\n",
      "Gesamt | Andere | IFO-l | IFO-r | ILF-l | ILF-r | SLF-l | SLF-r \n",
      "-------|--------|-------|-------|-------|-------|-------|-------\n",
      " 15334 | 12144.0 | 918.0 | 1037.0 | 376.0 | 330.0 | 530.0 | 695.0\n",
      "\n",
      "\n",
      "Iteration | # Annotations | # Annotierte Voxel |F1 Score\n",
      "----------|---------------|--------------------|--------\n",
      "        1 |          2940 |               2782 | 0.551\n",
      "        2 |          4378 |               4177 | 0.595\n",
      "        3 |          5830 |               5574 | 0.620\n",
      "        4 |          7287 |               6968 | 0.666\n",
      "        5 |          8743 |               8361 | 0.683\n",
      "       10 |         16030 |              15334 | 0.754\n"
     ]
    }
   ],
   "source": [
    "ns, ans, f1s, rf_preds, uncs_pc, uncs = train(method='ground-truth', n_epochs=10, measures=['ground-truth'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284b0a90",
   "metadata": {},
   "source": [
    "### Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "32aceef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selection using random\n",
      "Number of initial annotations: 1475.0\n",
      "Number of annotated Voxels: 1384\n",
      "Average F1 score for RF after initial user interaction:    0.467\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc8971977a0c4dac9959587519ccda73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "User interaction:   0%|          | 0/10 [00:00<?, ?iteration/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Durschnitt | Andere | IFO-l | IFO-r |  ILF-l | ILF-r | SLF-l | SLF-r \n",
      "-----------|--------|-------|-------|--------|-------|-------|--------\n",
      "      0.64 |   0.85 |  0.64 |  0.67 |   0.61 |  0.59 |  0.66 |  0.70\n",
      "\n",
      "\n",
      "Gesamt | Andere | IFO-l | IFO-r | ILF-l | ILF-r | SLF-l | SLF-r \n",
      "-------|--------|-------|-------|-------|-------|-------|-------\n",
      " 15245 | 12677.0 | 707.0 | 602.0 | 197.0 | 188.0 | 531.0 | 722.0\n",
      "\n",
      "\n",
      "Iteration | # Annotations | # Annotierte Voxel |F1 Score\n",
      "----------|---------------|--------------------|--------\n",
      "        1 |          2905 |               2783 | 0.519\n",
      "        2 |          4322 |               4183 | 0.542\n",
      "        3 |          5734 |               5582 | 0.569\n",
      "        4 |          7192 |               6981 | 0.589\n",
      "        5 |          8611 |               8379 | 0.596\n",
      "       10 |         15624 |              15245 | 0.645\n"
     ]
    }
   ],
   "source": [
    "ns_r, ans_r, f1s_r, rf_preds_r, uncs_pc_r, uncs_r = train(method='random', n_epochs=10, measures=['random'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "325a28c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selection using random\n",
      "Number of initial annotations: 1475.0\n",
      "Number of annotated Voxels: 1384\n",
      "Average F1 score for RF after initial user interaction:    0.467\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a260b72d77754fe89822d525bc754efa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "User interaction:   0%|          | 0/10 [00:00<?, ?iteration/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Durschnitt | Andere | IFO-l | IFO-r |  ILF-l | ILF-r | SLF-l | SLF-r \n",
      "-----------|--------|-------|-------|--------|-------|-------|--------\n",
      "      0.63 |   0.88 |  0.63 |  0.66 |   0.55 |  0.55 |  0.65 |  0.71\n",
      "\n",
      "\n",
      "Gesamt | Andere | IFO-l | IFO-r | ILF-l | ILF-r | SLF-l | SLF-r \n",
      "-------|--------|-------|-------|-------|-------|-------|-------\n",
      " 14949 | 12813.0 | 469.0 | 442.0 | 142.0 | 182.0 | 433.0 | 759.0\n",
      "\n",
      "\n",
      "Iteration | # Annotations | # Annotierte Voxel |F1 Score\n",
      "----------|---------------|--------------------|--------\n",
      "        1 |          2893 |               2783 | 0.498\n",
      "        2 |          4314 |               4183 | 0.518\n",
      "        3 |          5739 |               5583 | 0.529\n",
      "        4 |          6989 |               6825 | 0.543\n",
      "        5 |          8406 |               8224 | 0.557\n",
      "       10 |         15240 |              14949 | 0.625\n",
      "Selection using random\n",
      "Number of initial annotations: 1475.0\n",
      "Number of annotated Voxels: 1384\n",
      "Average F1 score for RF after initial user interaction:    0.467\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e7e5282bd994970a97dbd80754152e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "User interaction:   0%|          | 0/10 [00:00<?, ?iteration/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Durschnitt | Andere | IFO-l | IFO-r |  ILF-l | ILF-r | SLF-l | SLF-r \n",
      "-----------|--------|-------|-------|--------|-------|-------|--------\n",
      "      0.65 |   0.86 |  0.64 |  0.68 |   0.56 |  0.62 |  0.68 |  0.70\n",
      "\n",
      "\n",
      "Gesamt | Andere | IFO-l | IFO-r | ILF-l | ILF-r | SLF-l | SLF-r \n",
      "-------|--------|-------|-------|-------|-------|-------|-------\n",
      " 15195 | 12695.0 | 554.0 | 601.0 | 211.0 | 175.0 | 605.0 | 731.0\n",
      "\n",
      "\n",
      "Iteration | # Annotations | # Annotierte Voxel |F1 Score\n",
      "----------|---------------|--------------------|--------\n",
      "        1 |          2960 |               2783 | 0.526\n",
      "        2 |          4324 |               4138 | 0.528\n",
      "        3 |          5745 |               5538 | 0.553\n",
      "        4 |          7113 |               6871 | 0.578\n",
      "        5 |          8534 |               8270 | 0.593\n",
      "       10 |         15572 |              15195 | 0.646\n",
      "Selection using random\n",
      "Number of initial annotations: 1475.0\n",
      "Number of annotated Voxels: 1384\n",
      "Average F1 score for RF after initial user interaction:    0.467\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3961c669d53476381646cfc4e8e8779",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "User interaction:   0%|          | 0/10 [00:00<?, ?iteration/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Durschnitt | Andere | IFO-l | IFO-r |  ILF-l | ILF-r | SLF-l | SLF-r \n",
      "-----------|--------|-------|-------|--------|-------|-------|--------\n",
      "      0.66 |   0.85 |  0.65 |  0.69 |   0.63 |  0.61 |  0.66 |  0.71\n",
      "\n",
      "\n",
      "Gesamt | Andere | IFO-l | IFO-r | ILF-l | ILF-r | SLF-l | SLF-r \n",
      "-------|--------|-------|-------|-------|-------|-------|-------\n",
      " 15137 | 12584.0 | 694.0 | 661.0 | 262.0 | 170.0 | 537.0 | 665.0\n",
      "\n",
      "\n",
      "Iteration | # Annotations | # Annotierte Voxel |F1 Score\n",
      "----------|---------------|--------------------|--------\n",
      "        1 |          2919 |               2784 | 0.526\n",
      "        2 |          4228 |               4067 | 0.544\n",
      "        3 |          5666 |               5466 | 0.574\n",
      "        4 |          7129 |               6866 | 0.601\n",
      "        5 |          8543 |               8265 | 0.607\n",
      "       10 |         15573 |              15137 | 0.659\n",
      "Selection using random\n",
      "Number of initial annotations: 1475.0\n",
      "Number of annotated Voxels: 1384\n",
      "Average F1 score for RF after initial user interaction:    0.467\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2019626ff3c4756810dfc08205f67f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "User interaction:   0%|          | 0/10 [00:00<?, ?iteration/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Durschnitt | Andere | IFO-l | IFO-r |  ILF-l | ILF-r | SLF-l | SLF-r \n",
      "-----------|--------|-------|-------|--------|-------|-------|--------\n",
      "      0.65 |   0.86 |  0.66 |  0.66 |   0.62 |  0.58 |  0.68 |  0.70\n",
      "\n",
      "\n",
      "Gesamt | Andere | IFO-l | IFO-r | ILF-l | ILF-r | SLF-l | SLF-r \n",
      "-------|--------|-------|-------|-------|-------|-------|-------\n",
      " 15327 | 12895.0 | 639.0 | 525.0 | 225.0 | 158.0 | 604.0 | 632.0\n",
      "\n",
      "\n",
      "Iteration | # Annotations | # Annotierte Voxel |F1 Score\n",
      "----------|---------------|--------------------|--------\n",
      "        1 |          2896 |               2784 | 0.516\n",
      "        2 |          4302 |               4184 | 0.544\n",
      "        3 |          5743 |               5584 | 0.555\n",
      "        4 |          7172 |               6983 | 0.584\n",
      "        5 |          8632 |               8382 | 0.606\n",
      "       10 |         15678 |              15327 | 0.650\n",
      "Selection using random\n",
      "Number of initial annotations: 1475.0\n",
      "Number of annotated Voxels: 1384\n",
      "Average F1 score for RF after initial user interaction:    0.467\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab27bc63b51947b0b4ba1c09501c72e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "User interaction:   0%|          | 0/10 [00:00<?, ?iteration/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Durschnitt | Andere | IFO-l | IFO-r |  ILF-l | ILF-r | SLF-l | SLF-r \n",
      "-----------|--------|-------|-------|--------|-------|-------|--------\n",
      "      0.66 |   0.85 |  0.65 |  0.68 |   0.62 |  0.63 |  0.67 |  0.70\n",
      "\n",
      "\n",
      "Gesamt | Andere | IFO-l | IFO-r | ILF-l | ILF-r | SLF-l | SLF-r \n",
      "-------|--------|-------|-------|-------|-------|-------|-------\n",
      " 15369 | 12773.0 | 715.0 | 716.0 | 242.0 | 241.0 | 456.0 | 702.0\n",
      "\n",
      "\n",
      "Iteration | # Annotations | # Annotierte Voxel |F1 Score\n",
      "----------|---------------|--------------------|--------\n",
      "        1 |          2913 |               2783 | 0.520\n",
      "        2 |          4327 |               4183 | 0.536\n",
      "        3 |          5741 |               5582 | 0.568\n",
      "        4 |          7157 |               6981 | 0.580\n",
      "        5 |          8633 |               8380 | 0.611\n",
      "       10 |         15845 |              15369 | 0.659\n",
      "Selection using random\n",
      "Number of initial annotations: 1475.0\n",
      "Number of annotated Voxels: 1384\n",
      "Average F1 score for RF after initial user interaction:    0.467\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67f82d720d6c4416bd65dbefd5b8b887",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "User interaction:   0%|          | 0/10 [00:00<?, ?iteration/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Durschnitt | Andere | IFO-l | IFO-r |  ILF-l | ILF-r | SLF-l | SLF-r \n",
      "-----------|--------|-------|-------|--------|-------|-------|--------\n",
      "      0.65 |   0.87 |  0.66 |  0.67 |   0.61 |  0.61 |  0.67 |  0.69\n",
      "\n",
      "\n",
      "Gesamt | Andere | IFO-l | IFO-r | ILF-l | ILF-r | SLF-l | SLF-r \n",
      "-------|--------|-------|-------|-------|-------|-------|-------\n",
      " 15020 | 12867.0 | 660.0 | 465.0 | 262.0 | 168.0 | 532.0 | 451.0\n",
      "\n",
      "\n",
      "Iteration | # Annotations | # Annotierte Voxel |F1 Score\n",
      "----------|---------------|--------------------|--------\n",
      "        1 |          2898 |               2784 | 0.525\n",
      "        2 |          4356 |               4184 | 0.551\n",
      "        3 |          5824 |               5582 | 0.587\n",
      "        4 |          7262 |               6982 | 0.613\n",
      "        5 |          8390 |               8087 | 0.620\n",
      "       10 |         15405 |              15020 | 0.652\n",
      "Selection using random\n",
      "Number of initial annotations: 1475.0\n",
      "Number of annotated Voxels: 1384\n",
      "Average F1 score for RF after initial user interaction:    0.467\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1401c81170e4bc4b51c06ad334ad88a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "User interaction:   0%|          | 0/10 [00:00<?, ?iteration/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Durschnitt | Andere | IFO-l | IFO-r |  ILF-l | ILF-r | SLF-l | SLF-r \n",
      "-----------|--------|-------|-------|--------|-------|-------|--------\n",
      "      0.64 |   0.85 |  0.64 |  0.68 |   0.54 |  0.62 |  0.66 |  0.71\n",
      "\n",
      "\n",
      "Gesamt | Andere | IFO-l | IFO-r | ILF-l | ILF-r | SLF-l | SLF-r \n",
      "-------|--------|-------|-------|-------|-------|-------|-------\n",
      " 15111 | 12775.0 | 542.0 | 596.0 | 163.0 | 150.0 | 514.0 | 703.0\n",
      "\n",
      "\n",
      "Iteration | # Annotations | # Annotierte Voxel |F1 Score\n",
      "----------|---------------|--------------------|--------\n",
      "        1 |          2914 |               2784 | 0.531\n",
      "        2 |          4355 |               4183 | 0.561\n",
      "        3 |          5767 |               5583 | 0.557\n",
      "        4 |          7176 |               6983 | 0.570\n",
      "        5 |          8594 |               8383 | 0.586\n",
      "       10 |         15443 |              15111 | 0.643\n",
      "Selection using random\n",
      "Number of initial annotations: 1475.0\n",
      "Number of annotated Voxels: 1384\n",
      "Average F1 score for RF after initial user interaction:    0.467\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb78a3ec2c7f4589b3711b287948395b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "User interaction:   0%|          | 0/10 [00:00<?, ?iteration/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Durschnitt | Andere | IFO-l | IFO-r |  ILF-l | ILF-r | SLF-l | SLF-r \n",
      "-----------|--------|-------|-------|--------|-------|-------|--------\n",
      "      0.65 |   0.87 |  0.65 |  0.70 |   0.63 |  0.60 |  0.63 |  0.70\n",
      "\n",
      "\n",
      "Gesamt | Andere | IFO-l | IFO-r | ILF-l | ILF-r | SLF-l | SLF-r \n",
      "-------|--------|-------|-------|-------|-------|-------|-------\n",
      " 15367 | 13119.0 | 633.0 | 640.0 | 222.0 | 185.0 | 419.0 | 520.0\n",
      "\n",
      "\n",
      "Iteration | # Annotations | # Annotierte Voxel |F1 Score\n",
      "----------|---------------|--------------------|--------\n",
      "        1 |          2914 |               2779 | 0.515\n",
      "        2 |          4354 |               4178 | 0.544\n",
      "        3 |          5782 |               5578 | 0.561\n",
      "        4 |          7212 |               6978 | 0.579\n",
      "        5 |          8630 |               8376 | 0.601\n",
      "       10 |         15738 |              15367 | 0.653\n",
      "Selection using random\n",
      "Number of initial annotations: 1475.0\n",
      "Number of annotated Voxels: 1384\n",
      "Average F1 score for RF after initial user interaction:    0.467\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92fe741becb849dcb2a14c02ce8c1ba4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "User interaction:   0%|          | 0/10 [00:00<?, ?iteration/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Durschnitt | Andere | IFO-l | IFO-r |  ILF-l | ILF-r | SLF-l | SLF-r \n",
      "-----------|--------|-------|-------|--------|-------|-------|--------\n",
      "      0.64 |   0.85 |  0.65 |  0.69 |   0.58 |  0.60 |  0.65 |  0.70\n",
      "\n",
      "\n",
      "Gesamt | Andere | IFO-l | IFO-r | ILF-l | ILF-r | SLF-l | SLF-r \n",
      "-------|--------|-------|-------|-------|-------|-------|-------\n",
      " 15133 | 12771.0 | 604.0 | 657.0 | 171.0 | 183.0 | 447.0 | 659.0\n",
      "\n",
      "\n",
      "Iteration | # Annotations | # Annotierte Voxel |F1 Score\n",
      "----------|---------------|--------------------|--------\n",
      "        1 |          2779 |               2661 | 0.519\n",
      "        2 |          4211 |               4061 | 0.560\n",
      "        3 |          5644 |               5461 | 0.577\n",
      "        4 |          7051 |               6853 | 0.592\n",
      "        5 |          8493 |               8252 | 0.612\n",
      "       10 |         15492 |              15133 | 0.645\n",
      "Selection using random\n",
      "Number of initial annotations: 1475.0\n",
      "Number of annotated Voxels: 1384\n",
      "Average F1 score for RF after initial user interaction:    0.467\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae84c5a53ece48b080abe43d641a1d0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "User interaction:   0%|          | 0/10 [00:00<?, ?iteration/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Durschnitt | Andere | IFO-l | IFO-r |  ILF-l | ILF-r | SLF-l | SLF-r \n",
      "-----------|--------|-------|-------|--------|-------|-------|--------\n",
      "      0.65 |   0.85 |  0.63 |  0.68 |   0.62 |  0.62 |  0.66 |  0.71\n",
      "\n",
      "\n",
      "Gesamt | Andere | IFO-l | IFO-r | ILF-l | ILF-r | SLF-l | SLF-r \n",
      "-------|--------|-------|-------|-------|-------|-------|-------\n",
      " 15197 | 12803.0 | 617.0 | 624.0 | 221.0 | 215.0 | 426.0 | 680.0\n",
      "\n",
      "\n",
      "Iteration | # Annotations | # Annotierte Voxel |F1 Score\n",
      "----------|---------------|--------------------|--------\n",
      "        1 |          2945 |               2784 | 0.522\n",
      "        2 |          4271 |               4067 | 0.547\n",
      "        3 |          5675 |               5466 | 0.576\n",
      "        4 |          7015 |               6799 | 0.588\n",
      "        5 |          8466 |               8198 | 0.600\n",
      "       10 |         15586 |              15197 | 0.652\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    ns_r, ans_r, f1s_r, rf_preds_r, uncs_pc_r, uncs_r = train(method='random', n_epochs=10, measures=['random'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a0a9e1",
   "metadata": {},
   "source": [
    "### Totaly Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "05d92548",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selection using totaly-random\n",
      "Number of initial annotations: 1475.0\n",
      "Average F1 score for RF after initial user interaction:    0.4672\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc4d1c14a27848b2b1cc1145be756246",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "User interaction:   0%|          | 0/10 [00:00<?, ?iteration/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.86\n",
      "0.66\n",
      "0.69\n",
      "0.64\n",
      "0.62\n",
      "0.69\n",
      "0.72\n",
      "tensor([12558.,   728.,   692.,   278.,   188.,   598.,   780.])\n",
      "Iteration | # Annotations | Annotations-Verteilung |F1 Score\n",
      "----------|---------------|------------------------|--------\n",
      "        1 |          2909 | 0.5365\n",
      "        2 |          4346 | 0.5701\n",
      "        3 |          5781 | 0.5944\n",
      "        4 |          7213 | 0.6134\n",
      "        5 |          8658 | 0.6290\n",
      "       10 |         15822 | 0.6694\n"
     ]
    }
   ],
   "source": [
    "ns_r, ans_r, f1s_r, rf_preds_r, uncs_pc_r, uncs_r = train(method='totaly-random', n_epochs=10, measures=['totaly-random'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "244b5fc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Klasse 1: (tensor([-1.,  0.,  1.], dtype=torch.float64), tensor([ 183390, 2861184,    4051]))\n",
      "Klasse 2: (tensor([-1.,  0.,  1.], dtype=torch.float64), tensor([    582, 3007134,   40909]))\n",
      "Klasse 3: (tensor([-1.,  0.,  1.], dtype=torch.float64), tensor([    307, 3009528,   38790]))\n",
      "Klasse 4: (tensor([0., 1.], dtype=torch.float64), tensor([3045455,    3170]))\n",
      "Klasse 5: (tensor([-1.,  0.,  1.], dtype=torch.float64), tensor([  15093, 2967059,   66473]))\n"
     ]
    }
   ],
   "source": [
    "x = rf_preds[-1] - dataset.label\n",
    "print(f'Klasse 1: {x[0].unique(return_counts=True)}')\n",
    "print(f'Klasse 2: {x[1].unique(return_counts=True)}')\n",
    "print(f'Klasse 3: {x[2].unique(return_counts=True)}')\n",
    "print(f'Klasse 4: {x[3].unique(return_counts=True)}')\n",
    "print(f'Klasse 5: {x[4].unique(return_counts=True)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "52664ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([-1.,  0.], dtype=torch.float64), tensor([1063, 1567]))\n"
     ]
    }
   ],
   "source": [
    "mask = dataset.annotations.any(dim=0)\n",
    "y = dataset.annotations[:, mask] - dataset.label[:, mask]\n",
    "z = y.sum(dim=0)\n",
    "print(z.unique(return_counts=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1df06a66",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cc162e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_maps = [torch.ne(rf_prediction, dataset.label) * 1 for rf_prediction in rf_preds]\n",
    "error_maps_mean = [torch.any(error_map, dim=0) * 1 for error_map in error_maps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5ffbe52b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15243125, 3])\n"
     ]
    }
   ],
   "source": [
    "abc = uncs_pc[0]['entropy'].flatten()\n",
    "defg = uncs_pc[0]['spatial-distance'].flatten()\n",
    "hijk = uncs_pc[0]['feature-distance'].flatten()\n",
    "lmno = torch.stack((abc, defg, hijk), dim=1)\n",
    "print(lmno.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7d4c3a17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f058dea6791482e84fba4642a53dcc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculation:   0%|          | 0/20 [00:00<?, ?iteration/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Koeffizient für Iteration 1: Entropy: [[6.80838514]], SD: [[0.03420244]], FD: [[5.14872597]]\n",
      "Koeffizient für Iteration 1: Combined: [[ 6.72757369 -0.0340217   0.63251322]]\n",
      "Koeffizient für Iteration 2: Entropy: [[7.02794357]], SD: [[0.03219433]], FD: [[5.32265189]]\n",
      "Koeffizient für Iteration 2: Combined: [[ 6.73033755 -0.03509393  1.2549075 ]]\n",
      "Koeffizient für Iteration 3: Entropy: [[6.6982623]], SD: [[0.02620928]], FD: [[5.05152733]]\n",
      "Koeffizient für Iteration 3: Combined: [[ 6.29420073 -0.0529336   1.9025076 ]]\n",
      "Koeffizient für Iteration 4: Entropy: [[6.8116268]], SD: [[0.02158613]], FD: [[4.87395059]]\n",
      "Koeffizient für Iteration 4: Combined: [[ 6.59178342 -0.06249266  1.17257243]]\n",
      "Koeffizient für Iteration 5: Entropy: [[7.19238669]], SD: [[0.01998846]], FD: [[4.75844355]]\n",
      "Koeffizient für Iteration 5: Combined: [[ 7.08846542 -0.05720406  0.35012152]]\n",
      "Koeffizient für Iteration 6: Entropy: [[7.31138677]], SD: [[0.02119565]], FD: [[4.94982176]]\n",
      "Koeffizient für Iteration 6: Combined: [[ 7.19909338 -0.05252118  0.28792025]]\n",
      "Koeffizient für Iteration 7: Entropy: [[7.46501753]], SD: [[0.02088356]], FD: [[4.98891402]]\n",
      "Koeffizient für Iteration 7: Combined: [[ 7.32527822 -0.05210517  0.32009922]]\n",
      "Koeffizient für Iteration 8: Entropy: [[7.4728109]], SD: [[0.01655445]], FD: [[4.91746136]]\n",
      "Koeffizient für Iteration 8: Combined: [[ 7.25948023 -0.07076499  0.66780789]]\n",
      "Koeffizient für Iteration 9: Entropy: [[7.65695715]], SD: [[0.01807795]], FD: [[5.01641968]]\n",
      "Koeffizient für Iteration 9: Combined: [[ 7.44588136 -0.06067749  0.63144986]]\n",
      "Koeffizient für Iteration 10: Entropy: [[7.88620087]], SD: [[0.0149105]], FD: [[5.01443593]]\n",
      "Koeffizient für Iteration 10: Combined: [[ 7.63706198 -0.07136907  0.64764374]]\n",
      "Koeffizient für Iteration 11: Entropy: [[7.80623337]], SD: [[0.01361651]], FD: [[5.01710035]]\n",
      "Koeffizient für Iteration 11: Combined: [[ 7.55980865 -0.07544111  0.72586051]]\n",
      "Koeffizient für Iteration 12: Entropy: [[8.16946721]], SD: [[0.01329917]], FD: [[5.02519462]]\n",
      "Koeffizient für Iteration 12: Combined: [[ 7.86130355 -0.06921299  0.66288778]]\n",
      "Koeffizient für Iteration 13: Entropy: [[8.31745989]], SD: [[0.01391267]], FD: [[4.99480433]]\n",
      "Koeffizient für Iteration 13: Combined: [[ 8.1019051  -0.06081465  0.14810018]]\n",
      "Koeffizient für Iteration 14: Entropy: [[8.41426768]], SD: [[0.00948413]], FD: [[4.77357729]]\n",
      "Koeffizient für Iteration 14: Combined: [[ 8.16773366 -0.08207386  0.01620752]]\n",
      "Koeffizient für Iteration 15: Entropy: [[8.46227659]], SD: [[0.00888615]], FD: [[4.79644047]]\n",
      "Koeffizient für Iteration 15: Combined: [[ 8.1680069  -0.08400236  0.18326467]]\n",
      "Koeffizient für Iteration 16: Entropy: [[8.48307514]], SD: [[0.00942583]], FD: [[4.81521878]]\n",
      "Koeffizient für Iteration 16: Combined: [[ 8.22003659 -0.07857311  0.06067939]]\n",
      "Koeffizient für Iteration 17: Entropy: [[8.46032853]], SD: [[0.00933179]], FD: [[4.81248473]]\n",
      "Koeffizient für Iteration 17: Combined: [[ 8.17852393 -0.07791324  0.10570233]]\n",
      "Koeffizient für Iteration 18: Entropy: [[8.41374414]], SD: [[0.00800668]], FD: [[4.84997114]]\n",
      "Koeffizient für Iteration 18: Combined: [[ 8.11880232 -0.08526206  0.20948633]]\n",
      "Koeffizient für Iteration 19: Entropy: [[8.42593934]], SD: [[0.00739057]], FD: [[4.83043808]]\n",
      "Koeffizient für Iteration 19: Combined: [[ 8.12384395 -0.08665314  0.13084176]]\n",
      "Koeffizient für Iteration 20: Entropy: [[8.41835179]], SD: [[0.00618593]], FD: [[4.83350501]]\n",
      "Koeffizient für Iteration 20: Combined: [[ 8.07763439 -0.08778883  0.23979653]]\n"
     ]
    }
   ],
   "source": [
    "# Create and fit the logistic regression model\n",
    "for i, (unc_map, error_map) in enumerate(tqdm(zip(uncs_pc, error_maps),total=len(uncs_pc), desc='Calculation', unit='iteration')):\n",
    "    unc_map_e = unc_map['entropy'].flatten()\n",
    "    unc_map_sd = unc_map['spatial-distance'].flatten()\n",
    "    unc_map_fd = unc_map['feature-distance'].flatten()\n",
    "    logreg_e = LogisticRegression(random_state=0, n_jobs=-1)\n",
    "    logreg_e.fit(unc_map_e.reshape(-1, 1), error_map.flatten())\n",
    "    logreg_sd = LogisticRegression(random_state=0, n_jobs=-1)\n",
    "    logreg_sd.fit(unc_map_sd.reshape(-1, 1), error_map.flatten())\n",
    "    logreg_fd = LogisticRegression(random_state=0, n_jobs=-1)\n",
    "    logreg_fd.fit(unc_map_fd.reshape(-1, 1), error_map.flatten())\n",
    "    print(f\"Koeffizient für Iteration {i+1}: Entropy: {logreg_e.coef_}, SD: {logreg_sd.coef_}, FD: {logreg_fd.coef_}\")\n",
    "    logreg_c = LogisticRegression(random_state=0, n_jobs=-1)\n",
    "    logreg_c.fit(torch.stack((unc_map_e, unc_map_sd, unc_map_fd), dim=1), error_map.flatten())\n",
    "    print(f\"Koeffizient für Iteration {i+1}: Combined: {logreg_c.coef_}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
