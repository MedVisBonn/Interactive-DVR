{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "import nibabel as nib\n",
    "import nrrd\n",
    "import random\n",
    "from omegaconf import OmegaConf\n",
    "from typing import Iterable, Dict, Callable, Tuple, Union\n",
    "from scipy.ndimage import binary_erosion, binary_dilation\n",
    "import random\n",
    "\n",
    "\n",
    "sys.path.append('..')\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserModel:\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        ground_truth: Tensor, \n",
    "        cfg: dict, \n",
    "        brush_sizes=torch.arange(2,7)\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        # globals\n",
    "        self.gt = ground_truth.float() # nd array or float tensor?\n",
    "        if cfg['brush']:\n",
    "            self.brush_sizes = brush_sizes\n",
    "        else:\n",
    "            self.brush_sizes = [1]\n",
    "        \n",
    "        if cfg['slice_selection'] == 'mean':\n",
    "            self.slice_selection = 'mean'\n",
    "        elif cfg['slice_selection'] == 'max':\n",
    "            self.slice_selection = 'max'\n",
    "        else:\n",
    "            raise ValueError('Invalid slice selection method. Choose between \"mean\" and \"max\".')\n",
    "\n",
    "        if cfg['voxel_selection'] == 'mean':\n",
    "            self.voxel_selection = 'mean'\n",
    "        elif cfg['voxel_selection'] == 'max':\n",
    "            self.voxel_selection = 'max'\n",
    "        else:\n",
    "            raise ValueError('Invalid voxel selection method. Choose between \"mean\" and \"max\".')\n",
    "        \n",
    "        \n",
    "        \n",
    "        # statistics to track\n",
    "        self.annotated_pixels = None\n",
    "        self.annotated_slices = None\n",
    "        \n",
    "    \n",
    "    def _sum_l1_per_slice(\n",
    "        self, \n",
    "        volume: Tensor\n",
    "    ) -> Tensor:\n",
    "        \"\"\" Find sum over all slices in each direction\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        volume : Tensor \n",
    "            shape L x W x H with L = W = H  \n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        out : Tensor\n",
    "            (N, n) shaped array holding slice sums, where N is\n",
    "            the dimensionality (3) and n the number of slices in each\n",
    "            direction (L, W, H). Expects zero padding to ensure same length\n",
    "            across dimensions.\n",
    "        \"\"\"\n",
    "\n",
    "        assert((volume.shape[0] == volume.shape[1]) and (volume.shape[0] == volume.shape[2]))\n",
    "\n",
    "        # dimensionality and array of possible axis for volume\n",
    "        dims    = len(volume.shape)\n",
    "        indices = torch.arange(dims)\n",
    "        sums    = torch.zeros((dims, volume.shape[0]))\n",
    "\n",
    "        # for each direction, sum values in each slice\n",
    "        for dim in range(dims):\n",
    "            axis       = tuple(indices[indices != dim])\n",
    "            slice_sums = volume.sum(axis=axis)\n",
    "            sums[dim]  = slice_sums\n",
    "        return sums\n",
    "        \n",
    "        \n",
    "\n",
    "    def _order_slices_by_sum(\n",
    "        self, \n",
    "        slice_sums: Tensor\n",
    "    ) -> Union[np.array, np.array]:\n",
    "        \"\"\" Order slices by their overall sum\n",
    "        Note: numpy dependent, because np.unravel_index exists\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        slice_sums : Tensor\n",
    "            shape (N, n) with N=3 and n=L=H=W\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        axis : 1d array\n",
    "            axis of slices in descending order w.r.t.\n",
    "            their slice sum\n",
    "        slices : 1d array\n",
    "            slice index of slices in descending order\n",
    "            w.r.t. their slice sum\n",
    "        \"\"\"\n",
    "\n",
    "        length = slice_sums.shape[0]\n",
    "\n",
    "        # calculate direction (axis) and indices of slices in \n",
    "        # descending order w.r.t. their slice sum\n",
    "        sorted_slice_indices = torch.argsort(slice_sums.flatten(), descending=True)\n",
    "        # Note: Unravel_index is not yet implemented in torch, but a requested feature\n",
    "        #       as of Dec 2020. Maybe add later. \n",
    "        axis, slices = np.unravel_index(sorted_slice_indices, slice_sums.shape)\n",
    "        \n",
    "        return axis, slices\n",
    "\n",
    "\n",
    "    def _slice_samples_per_class(\n",
    "        self, \n",
    "        slc: Tensor, \n",
    "        inverse_frequencies: Tensor,\n",
    "        n: int\n",
    "    ) -> Tensor:\n",
    "        \"\"\" samples seeds for each class in a slice from the\n",
    "            error map, weighted by inverse class frequencies\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        slc : Tensor\n",
    "            slice from error map, shape n_classes x W x H\n",
    "\n",
    "        inverse_frequencies : Tensor\n",
    "            inverse class frequencies from ground truth, shape n_classes x 1 x 1 x 1\n",
    "\n",
    "        n : int\n",
    "            number of seeds\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        n_samples : Tensor\n",
    "            shape n_classes\n",
    "\n",
    "        \"\"\"\n",
    "        # omit sign for number of misclassifications\n",
    "        slc_abs = torch.abs(slc)\n",
    "\n",
    "        # calculate proportions by dividing total number of \n",
    "        # misclassifications by class frequency for each class\n",
    "        # and then normalize to stochastic vector\n",
    "        total                  = slc_abs.sum(dim=(1,2))\n",
    "        proportions            = total * inverse_frequencies.flatten()\n",
    "        proportions_normalized = proportions / proportions.sum()\n",
    "\n",
    "        # quantize sample proportions to get preliminary number\n",
    "        # of samples\n",
    "        n_samples = (proportions_normalized * n).type(torch.int)\n",
    "\n",
    "        # catch cases where int conversion results in a number of\n",
    "        # samples that is different from n and correct them.\n",
    "        # Current strategy: minimal impact by removing and adding\n",
    "        # to dominant class\n",
    "        while ( n_samples.sum() != n ):\n",
    "            # in case of undershoot, add samples to class\n",
    "            # with highest number of overall samples\n",
    "            if n_samples.sum() < n:\n",
    "                n_samples[np.argmax(proportions_normalized)] += 1\n",
    "\n",
    "            # in case of overshoot, remove samples from class\n",
    "            # with highest number of overall samples        \n",
    "            else:\n",
    "                n_samples[np.argmax(proportions_normalized)] -= 1\n",
    "        return n_samples\n",
    "\n",
    "\n",
    "    def _sample_candidate_voxels(\n",
    "        self, slc: Tensor, \n",
    "        ground_truth_slice: Tensor, \n",
    "        n_class_samples: Tensor, \n",
    "        seed=None\n",
    "    ) -> Tensor:\n",
    "        \"\"\" individually sample voxels for each class with samples sizes\n",
    "            potentially varying among them.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        slc : Tensor\n",
    "            slice from error map, shape n_classes x W x H\n",
    "            \n",
    "        ground_truth_slice : Tensor\n",
    "            ground truth slice, shape n_classes x W x H\n",
    "            \n",
    "        n_class_samples : Tensor\n",
    "            number of samples for each class, shape n_classes\n",
    "            \n",
    "        seed : int\n",
    "            If not None (default), set specified seed\n",
    "            before sampling.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        samples : Tensor\n",
    "            mask with samples for specified slice and all classes,\n",
    "            shape n_classes x W x H\n",
    "        \"\"\"\n",
    "\n",
    "        # seed if specified\n",
    "        if seed is not None:\n",
    "            torch.manual_seed(seed)\n",
    "\n",
    "        # init sampler and output tensor\n",
    "        sampler = torch.utils.data.WeightedRandomSampler\n",
    "        samples = torch.zeros_like(slc)\n",
    "\n",
    "        #weights = torch.any(torch.abs(slc).type(torch.uint8), axis=0) * ground_truth_slice # 5 x 145 x 145 , alte Version\n",
    "        weights = torch.abs(slc).max(dim=0).values * ground_truth_slice # 5 x 145 x 145 , neue Version\n",
    "\n",
    "        # print(weights.shape, (weights>0).sum(axis=(1,2)))\n",
    "        weights = weights / (weights>0).sum(axis=(1,2)).reshape(-1,1,1)\n",
    "        # iterate over classes, sampling for each independently\n",
    "        for weight, num_samples, i in zip(weights, n_class_samples, range(slc.shape[0])):\n",
    "            \n",
    "            # generate uniform weights for false negative voxels\n",
    "            # weight = (volume > 0) / (volume > 0).sum()\n",
    "            # upper bound for number of samples to maximum in slice\n",
    "            max_samples = (weight > 0).sum()\n",
    "            num_samples = int(min(max_samples, num_samples))\n",
    "            # catch case where number of samples is zero for a class\n",
    "            if num_samples > 0:\n",
    "                # 1D coordinates for samples from weight matrix\n",
    "                #print(num_samples)\n",
    "                index_list = list(sampler(weight.flatten(), num_samples=num_samples, replacement=False))\n",
    "                # 2D coordinates for samples from weight matrix\n",
    "                index_coords = np.unravel_index(index_list, weight.shape)\n",
    "                # apply mask via coordinates to samples for class i\n",
    "                #samples[i][index_coords] = 1   # alte Version, annotiert nur aktuell betrachtete Klasse\n",
    "                samples[:, index_coords] = ground_truth_slice[:, index_coords]\n",
    "                #print(index_coords)\n",
    "\n",
    "        return samples\n",
    "\n",
    "    def sample_random_candidate_voxels(\n",
    "        self, \n",
    "        slc: Tensor, \n",
    "        ground_truth_slice: Tensor, \n",
    "        n_samples, \n",
    "        seed=None\n",
    "    ) -> Tensor:\n",
    "\n",
    "        # seed if specified\n",
    "        #if seed is not None:\n",
    "        #    torch.manual_seed(seed)\n",
    "\n",
    "        # init sampler and output tensor\t\n",
    "        sampler = torch.utils.data.WeightedRandomSampler\n",
    "        samples = torch.zeros_like(slc)\n",
    "\n",
    "        weights = torch.any(torch.abs(slc).type(torch.uint8), axis=0) # 145 x 145\n",
    "        weights = weights / (weights>0).sum(axis=(0,1))\n",
    "\n",
    "        num_samples = int(min((weights > 0).sum(), n_samples))\n",
    "\n",
    "        index_list = list(sampler(weights.flatten(), num_samples=num_samples, replacement=False))\n",
    "        index_coords = np.unravel_index(index_list, weights.shape)\n",
    "\n",
    "        samples[:, index_coords] = ground_truth_slice[:, index_coords]\n",
    "\n",
    "        return samples # has to have shape [5, 145, 145]\n",
    "\n",
    "\n",
    "\n",
    "    def _slice_add_neighbors(self, class_samples: Tensor, ground_truth_slice: Tensor) -> Tensor:\n",
    "        \"\"\" creates slice with all sampled interaction candidates and their\n",
    "            neighborhoods for each class\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        class_samples : Tensor\n",
    "            sampled seed mask, shape n_classes x W x H \n",
    "    \n",
    "        ground_truth : Tensor\n",
    "            ground truth slice, shape n_classes x W x H \n",
    "\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        interaction_mask : Tensor\n",
    "            mask with added neighbors from brushing,\n",
    "            shape n_classes x W x H\n",
    "        \"\"\"\n",
    "        interaction_mask           = torch.zeros_like(class_samples, dtype=torch.int64)\n",
    "        vectorized_binary_erosion  = np.vectorize(binary_erosion,  signature='(j,i),(k,k)->(j,i)')\n",
    "        vectorized_binary_dilation = np.vectorize(binary_dilation, signature='(j,i),(k,k)->(j,i)')\n",
    "\n",
    "\n",
    "        for size in self.brush_sizes:\n",
    "            brush             = torch.ones((size,size))\n",
    "            brushable_samples = class_samples * torch.tensor(vectorized_binary_erosion(ground_truth_slice, structure=brush))\n",
    "            brushed_samples   = vectorized_binary_dilation(brushable_samples, structure=brush).astype(int)\n",
    "            interaction_mask  = torch.bitwise_or(interaction_mask, torch.tensor(brushed_samples))\n",
    "        \n",
    "        return interaction_mask\n",
    "\n",
    "\n",
    "    \n",
    "    def initial_annotation(\n",
    "        self, \n",
    "        n_samples: int, \n",
    "        init: str = 'three_slices', \n",
    "        pos_weight: float = 1, \n",
    "        seed: int = 42\n",
    "    ) -> Tensor:        \n",
    "        \"\"\" creates the initial annotations. For each direction (saggital, coronal,\n",
    "            axial), select the slice with the most foreground labels (3 in total).\n",
    "            (2) For each slice, sample n_samples many seeding points and\n",
    "                save their position in an annotation mask.\n",
    "            (3) Apply the largest quadratic brush (from a given range) to each seed\n",
    "                for which all affected voxels are foreground and add them to\n",
    "                the annotation mask as well.\n",
    "            (4) Mask the ground truth labels with the annotation mask and return.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        n_samples : int\n",
    "            number of seed points for each slice. Not needed when \n",
    "            init = paper_init\n",
    "        \n",
    "        init : str\n",
    "            'three_slices': Finds three slices (one in each direction) that have\n",
    "                a high label densety across all classes and then annotates them\n",
    "                partly.\n",
    "            'paper_init': the initial annotation matches the annotation used in \n",
    "                preliminary paper.\n",
    "            'per_class': For each class, finds one slice with high label density\n",
    "                and annotates it partly. The annotations per slice are distributed\n",
    "                according to #TODO\n",
    "        \n",
    "        pos_weight : weight for forground vs background samples per slice. Only used\n",
    "            if init='per_class'.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        interaction_map : Tensor\n",
    "            shape n_classes x L x W x H\n",
    "\n",
    "        \"\"\"\n",
    "        interaction_map = torch.zeros_like(self.gt).int()\n",
    "        if init == 'paper_init':\n",
    "            # [(\"sagittal\", 72) -> 72, (\"coronal\", 87) -> 72, (\"axial\", 72) -> 72]\n",
    "            \n",
    "            for orientation in range(3):\n",
    "                selection = [slice(None)] * 4\n",
    "                if orientation == 0:\n",
    "                    selection[orientation + 1]  = [73]\n",
    "                else:\n",
    "                    selection[orientation + 1]  = [72]\n",
    "                interaction_map[selection] = self.gt[selection]\n",
    "\n",
    "        elif init == 'three_slices':\n",
    "            n_classes = self.gt.shape[0]\n",
    "            #t = self.gt\n",
    "\n",
    "            inverse_size_weights = self.gt.mean((1,2,3)).sum() / self.gt.mean((1,2,3)).reshape((n_classes,1,1,1))\n",
    "            \n",
    "            \n",
    "            t_norm = torch.norm(self.gt * inverse_size_weights, p=1, dim=0)\n",
    "\n",
    "            # 1.1) calc sum over l1 norms, e.g. for the l1 norms for segmentation predictions\n",
    "            slice_sums = self._sum_l1_per_slice(t_norm)\n",
    "\n",
    "            # 1.2) order slices in descending order by their sum\n",
    "            axis, indices = self._order_slices_by_sum(slice_sums)\n",
    "\n",
    "            # save data location for later sub - sampling\n",
    "            data_location = []\n",
    "\n",
    "            # select one slice for each direction in volume.\n",
    "            for orientation in range(3):\n",
    "                #Use the ordered slice list to find best slice for each direction\n",
    "                selection = [slice(None)] * 4\n",
    "                index     = indices[np.argmax(axis == orientation)]\n",
    "                selection[orientation+1] = index\n",
    "                # select slice from misclassifications and ground truth\n",
    "                t_selection = self.gt[selection]\n",
    "\n",
    "                # samples voxels and add their neighborhood to 2D mask\n",
    "                n_class_samples = self._slice_samples_per_class(t_selection, inverse_size_weights, n_samples)\n",
    "                #print(n_class_samples.sum())\n",
    "                #print(t_selection.shape, n_class_samples)\n",
    "\n",
    "                class_samples = self._sample_candidate_voxels(t_selection, t_selection, n_class_samples=n_class_samples, seed=seed)\n",
    "                brushed_mask  = self._slice_add_neighbors(class_samples, t_selection)\n",
    "                # make interaction map with same shape as model input\n",
    "                interaction_map[selection] = torch.bitwise_or(interaction_map[selection], brushed_mask)\n",
    "                # interaction_map[selection] = ((interaction_map[selection].sum(0) * t_selection) > 0) * 1\n",
    "                data_location.append((orientation, index))\n",
    "        \n",
    "        elif init == 'per_class':\n",
    "            n_classes = self.gt.shape[0]\n",
    "            data_location = []\n",
    "            inverse_size_weights = self.gt.mean((1,2,3)).sum() / self.gt.mean((1,2,3)).reshape((n_classes,1,1,1))\n",
    "            \n",
    "            for c in range(n_classes):\n",
    "                cweight = torch.eye(n_classes)[c].view(n_classes, 1, 1, 1)\n",
    "                t_norm = torch.norm(self.gt * cweight, p=1, dim=0)\n",
    "                slice_sums = self._sum_l1_per_slice(t_norm)\n",
    "                axis, indices = self._order_slices_by_sum(slice_sums)\n",
    "                \n",
    "                selection = [slice(None)] * 4\n",
    "                selection[axis[0] + 1] = indices[0]\n",
    "                \n",
    "                t_selection = self.gt[selection]\n",
    "                \n",
    "                slice_sample_weights = inverse_size_weights * cweight * n_classes / (n_classes+1) * pos_weight + \\\n",
    "                                    inverse_size_weights * (1-cweight) / ( (n_classes+1) * (n_classes-1) )\n",
    "                \n",
    "                n_class_samples = self._slice_samples_per_class(t_selection, slice_sample_weights, n_samples)\n",
    "                #print(n_class_samples, n_samples)\n",
    "                class_samples = self._sample_candidate_voxels(t_selection, t_selection, n_class_samples=n_class_samples, seed=seed)\n",
    "\n",
    "                brushed_mask  = self._slice_add_neighbors(class_samples, t_selection)\n",
    "                interaction_map[selection] = torch.bitwise_or(interaction_map[selection], brushed_mask)\n",
    "                data_location.append((axis[0], indices[0]))\n",
    "\n",
    "        return interaction_map.float()\n",
    "        \n",
    "            \n",
    "    def refinement_annotation(\n",
    "        self,\n",
    "        prediction: Tensor, \n",
    "        annotation_mask: Tensor, \n",
    "        uncertainty_map: Tensor,\n",
    "        n_samples: int, \n",
    "        mode: int = 'single_slice', \n",
    "        pos_weight: float = 1, \n",
    "        seed: int = 42\n",
    "    ) -> Tensor:\n",
    "        \"\"\" Finds the slice with the worst prediction across all three axis and \n",
    "            annotates parts of it. The annotation happens in multiple steps:\n",
    "            (1) mask all voxels that are already annotated with annotation_mask\n",
    "            (2) Sample n_samples many seeding points and save their position in\n",
    "                an annotation mask\n",
    "            (3) Apply the largest quadratic brush (from a given range) to each seed\n",
    "                for which all affected voxels are foreground and add them to\n",
    "                the annotation mask as well.\n",
    "            (4) Mask the ground truth labels with the annotation mask and return\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        prediction : Tensor\n",
    "            predictions of segmentation model with\n",
    "            shape n_classes x L x W x H\n",
    "\n",
    "        annotation_mask : Tensor\n",
    "            current annotation, shape n_classes x L x W x H\n",
    "\n",
    "        n_samples : int\n",
    "            number of samples per slice before brushing\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        interaction_map : Tensor\n",
    "            new annotations, shape n_classes x L x W x H\n",
    "\n",
    "        \"\"\"\n",
    "        n_classes = prediction.shape[0]\n",
    "\n",
    "        # calculate inverse class frequencies\n",
    "        inverse_size_weights = self.gt.mean((1,2,3)).sum() / self.gt.mean((1,2,3)).reshape((n_classes,1,1,1))\n",
    "\n",
    "        # calculate mask for available voxels\n",
    "        #available_voxels = 1 - annotation_mask.float() # alte Version\n",
    "        available_voxels = 1 - torch.any(annotation_mask, dim=0, keepdim=True) * 1\n",
    "\n",
    "        # calculate difference between truth and prediction, i.e. misclassified voxels\n",
    "        if uncertainty_map != None:\n",
    "            diff = uncertainty_map * available_voxels\n",
    "        else:\n",
    "            diff = torch.abs(self.gt - prediction.float()) * available_voxels\n",
    "        # print(\"weights:\",inverse_size_weights.flatten())\n",
    "        \n",
    "        \n",
    "        if mode == 'single_slice':\n",
    "            # norm over classes weighted by inverse class frequency - importance weight for sampling\n",
    "            diff_norm = torch.norm(diff  * inverse_size_weights, p=1, dim=0)\n",
    "\n",
    "            # 1.1) calc sum over l1 norms, e.g. for the l1 norms for segmentation predictions\n",
    "            slice_sums = self._sum_l1_per_slice(diff_norm)\n",
    "\n",
    "            # 1.2) order slices in descending order by their sum\n",
    "            axis, indices = self._order_slices_by_sum(slice_sums)\n",
    "\n",
    "            # 2.0) select slice with highest importance weight over all axes\n",
    "            random_selection = np.random.randint(0,6)\n",
    "            ax  = axis[0]\n",
    "            slc = indices[0]\n",
    "            data_location = (ax, slc)\n",
    "            selection = [slice(None)] + [slice(None)] * 3\n",
    "            selection[ax + 1] = slc\n",
    "\n",
    "            # 2.1) calculate number of samples for each class from a raw difference slice\n",
    "            diff_selection  = diff[selection]\n",
    "            t_selection     = self.gt[selection]\n",
    "            n_class_samples = self._slice_samples_per_class(diff_selection, inverse_size_weights, n_samples)\n",
    "            #print(n_class_samples.sum())\n",
    "\n",
    "            # 2.2) for each class, sample from false negatives as often as specified in n_class_samples\n",
    "            class_samples = self._sample_candidate_voxels(diff_selection, t_selection, n_class_samples=n_class_samples, seed=seed)\n",
    "\n",
    "            # 2.3) brush all samples with maximum brush from list of brushes\n",
    "            brushed_mask = self._slice_add_neighbors(class_samples, t_selection)\n",
    "\n",
    "            # 2.4) create interaction map to return\n",
    "            interaction_map = torch.zeros_like(self.gt, dtype=torch.int64)\n",
    "            interaction_map[selection] = torch.bitwise_or(interaction_map[selection], brushed_mask)\n",
    "            # interaction_map[selection] = ((interaction_map[selection].sum(0) * t_selection) > 0) * 1\n",
    "                \n",
    "        elif mode == 'per_class':\n",
    "            data_location = []\n",
    "            interaction_map = torch.zeros_like(self.gt, dtype=torch.int64)\n",
    "            for c in range(n_classes):\n",
    "                cweight = torch.eye(n_classes)[c].view(n_classes, 1, 1, 1)\n",
    "                diff_norm = torch.norm(diff * cweight, p=1, dim=0) # 145, 145, 145, binär\n",
    "\n",
    "                # 1.1) calc sum over l1 norms, e.g. for the l1 norms for segmentation predictions\n",
    "                slice_sums = self._sum_l1_per_slice(diff_norm)  # 3, 145\n",
    "\n",
    "                # 1.2) order slices in descending order by their sum\n",
    "                axis, indices = self._order_slices_by_sum(slice_sums)\n",
    "\n",
    "                # 2.0) select slice with highest importance weight over all axes\n",
    "                random_selection = np.random.randint(0,6)\n",
    "                ax  = axis[0]\n",
    "                slc = indices[0]\n",
    "                \n",
    "                selection = [slice(None)] + [slice(None)] * 3\n",
    "                selection[ax + 1] = slc\n",
    "\n",
    "                # 2.1) calculate number of samples for each class from a raw difference slice\n",
    "                diff_selection  = diff[selection]\n",
    "                t_selection     = self.gt[selection]\n",
    "                \n",
    "                slice_sample_weights = inverse_size_weights * cweight * n_classes / (n_classes+1) * pos_weight + \\\n",
    "                                    inverse_size_weights * (1-cweight) / ( (n_classes+1) * (n_classes-1) )\n",
    "                \n",
    "                n_class_samples = self._slice_samples_per_class(t_selection, slice_sample_weights, n_samples)\n",
    "                #print(n_class_samples, n_samples)\n",
    "                \n",
    "                # 2.2) for each class, sample from false negatives as often as specified in n_class_samples\n",
    "                class_samples = self._sample_candidate_voxels(diff_selection, t_selection, n_class_samples=n_class_samples, seed=seed)\n",
    "\n",
    "                # 2.3) brush all samples with maximum brush from list of brushes\n",
    "                brushed_mask = self._slice_add_neighbors(class_samples, t_selection)\n",
    "\n",
    "                # 2.4) create interaction map to return\n",
    "                interaction_map[selection] = torch.bitwise_or(interaction_map[selection], brushed_mask)\n",
    "                data_location.append((axis[0], indices[0]))\n",
    "                \n",
    "        return interaction_map.float() # , selection\n",
    "    \n",
    "    \n",
    "    def random_refinement_annotation(\n",
    "        self, \n",
    "        prediction: Tensor, \n",
    "        annotation_mask: Tensor,\n",
    "        brain_mask: Tensor, \n",
    "        n_samples: int, \n",
    "        mode: int = 'single_slice', \n",
    "        pos_weight: float = 1, \n",
    "        seed: int = 42\n",
    "    ) -> Tensor:\n",
    "        \"\"\" Finds the slice with the highest uncertainty across all three axis and \n",
    "            annotates parts of it. The annotation happens in multiple steps:\n",
    "            (1) mask all voxels that are already annotated with annotation_mask\n",
    "            (2) Sample n_samples many seeding points and save their position in\n",
    "                an annotation mask\n",
    "            (3) Apply the largest quadratic brush (from a given range) to each seed\n",
    "                for which all affected voxels are foreground and add them to\n",
    "                the annotation mask as well.\n",
    "            (4) Mask the ground truth labels with the annotation mask and return\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        prediction : Tensor\n",
    "            predictions of segmentation model with\n",
    "            shape n_classes x L x W x H\n",
    "\n",
    "        annotation_mask : Tensor\n",
    "            current annotation, shape n_classes x L x W x H\n",
    "\n",
    "        n_samples : int\n",
    "            number of samples per slice before brushing\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        interaction_map : Tensor\n",
    "            new annotations, shape n_classes x L x W x H\n",
    "\n",
    "        \"\"\"\n",
    "        n_classes = prediction.shape[0]\n",
    "\n",
    "        # calculate inverse class frequencies\n",
    "        inverse_size_weights = self.gt.mean((1,2,3)).sum() / self.gt.mean((1,2,3)).reshape((n_classes,1,1,1))\n",
    "\n",
    "        # calculate mask for available voxels\n",
    "        available_voxels = 1 - torch.any(annotation_mask, dim=0, keepdim=True) * 1\n",
    "    \t\n",
    "        annotated_voxels = torch.any(annotation_mask, axis=0)\n",
    "        brain_not_annoated_mask = brain_mask & ~annotated_voxels\n",
    "        x = torch.zeros((5,145,145,145))\n",
    "        x[:, brain_not_annoated_mask] = 1     # 5, 145, 145, 145\n",
    "        random_mask = torch.zeros((145,145,145))\n",
    "        random_mask[brain_not_annoated_mask] = 1   # 145, 145, 145\n",
    "\n",
    "        if mode == 'single_slice':\n",
    "            #np.random.seed(seed)\n",
    "            random_axis = np.random.randint(0,3)\n",
    "            match random_axis:\n",
    "                case 0:\n",
    "                    sclice_sums = torch.sum(random_mask, axis=(1,2))\n",
    "                case 1:\n",
    "                    sclice_sums = torch.sum(random_mask, axis=(0,2))\n",
    "                case 2:\n",
    "                    sclice_sums = torch.sum(random_mask, axis=(0,1))\n",
    "\n",
    "            valid_slice_indices = torch.where(sclice_sums >= n_samples)[0]\n",
    "            random_slice_index = np.random.choice(valid_slice_indices)     \n",
    "\n",
    "            ax = random_axis\n",
    "            slc = random_slice_index\n",
    "            #print(ax, slc)\n",
    "            data_location = (ax, slc)\n",
    "            selection = [slice(None)] + [slice(None)] * 3\n",
    "            selection[ax + 1] = slc\n",
    "\n",
    "            random_selection = x[selection]\n",
    "            t_selection = self.gt[selection]\n",
    "\n",
    "            samples = self.sample_random_candidate_voxels(random_selection, t_selection, n_samples)\n",
    "            brushed_mask = self._slice_add_neighbors(samples, t_selection)\n",
    "\n",
    "            interaction_map = torch.zeros_like(self.gt, dtype=torch.int64)\n",
    "            interaction_map[selection] = torch.bitwise_or(interaction_map[selection], brushed_mask)\n",
    "\n",
    "        elif mode == 'per_class':\n",
    "            data_location = []\n",
    "            interaction_map = torch.zeros_like(self.gt, dtype=torch.int64)\n",
    "            for c in range(n_classes):\n",
    "                slice_sums = self._sum_l1_per_slice(random_mask)\n",
    "                random_axis = np.random.randint(0,3)\n",
    "                match random_axis:\n",
    "                    case 0:\n",
    "                        slice_sums = slice_sums[0]\n",
    "                    case 1:\n",
    "                        slice_sums = slice_sums[1]\n",
    "                    case 2:\n",
    "                        slice_sums = slice_sums[2]\n",
    "                \n",
    "                valid_slice_indices = torch.argwhere(slice_sums > 0).flatten()    # NOTE: oder größer gleich n_samples?\n",
    "                random_slice_index = np.random.choice(valid_slice_indices)\n",
    "\n",
    "                ax = random_axis\n",
    "                slc = random_slice_index\n",
    "\n",
    "                selection = [slice(None)] + [slice(None)] * 3\n",
    "                selection[ax + 1] = slc\n",
    "                random_selection = x[selection]\n",
    "                t_selection = self.gt[selection]\n",
    "\n",
    "                samples = self.sample_random_candidate_voxels(random_selection, t_selection, n_samples, seed=seed)\n",
    "                brushed_mask = self._slice_add_neighbors(samples, t_selection)\n",
    "                interaction_map[selection] = torch.bitwise_or(interaction_map[selection], brushed_mask)\n",
    "                \n",
    "        return interaction_map.float() # , selection\n",
    "\n",
    "\n",
    "\n",
    "    def novelty_refinement_annotation(\n",
    "        self,\n",
    "        annotation_mask: Tensor, \n",
    "        novelty_map: Tensor,\n",
    "        n_samples: int, \n",
    "        mode: int = 'single_slice', \n",
    "        pos_weight: float = 1, \n",
    "        seed: int = 42\n",
    "    ):\n",
    "        \n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AEDataset(Dataset):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        subject_id: str,\n",
    "        cfg, \n",
    "        modality='reconstruction', \n",
    "        mode='train', \n",
    "        set=1, \n",
    "        # normalize=True,\n",
    "        augment=False, \n",
    "        localize=False, \n",
    "        balance=False, \n",
    "        to_gpu=True, \n",
    "        init='three_slices', \n",
    "        smooth_label=False\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.cfg          = cfg\n",
    "        self.cfg['rank']  = 0\n",
    "        self.modality     = modality\n",
    "        self.mode         = mode\n",
    "        self.augment      = augment\n",
    "        self.to_gpu       = to_gpu\n",
    "        self.init         = init\n",
    "        self.smooth_label = smooth_label\n",
    "        self.localize     = localize\n",
    "        self.balance      = balance\n",
    "\n",
    "        data_path = os.path.join(\n",
    "            cfg[\"data_dir\"], \n",
    "            subject_id, \n",
    "            \"Diffusion\", \n",
    "            \"data.nii.gz\"\n",
    "        )\n",
    "        data_in = torch.tensor(nib.load(data_path).get_fdata()).float()\n",
    "        mask_path = os.path.join(\n",
    "            cfg[\"data_dir\"], \n",
    "            subject_id, \n",
    "            \"Diffusion\", \n",
    "            \"nodif_brain_mask.nii.gz\"\n",
    "        ).permute(1,0,2)\n",
    "        brain_mask = torch.tensor(\n",
    "            nib.load(brain_mask).get_fdata(), dtype=torch.bool).permute(1,0,2)\n",
    "        tract_path = os.path.join(\n",
    "            cfg[\"data_dir\"], \n",
    "            subject_id, \n",
    "            \"tracts_masks\"\n",
    "        )\n",
    "\n",
    "\n",
    "        # shape [12, 145, 145, 145]    [classes, B, H, W]\n",
    "        self.tract_masks = torch.load(cfg['data_dir'] + 'tract_masks/complete.pt').permute(0,2,1,3)\n",
    "        \n",
    "        self.set = set\n",
    "        if set == 1:\n",
    "            cfg['labels'] = [\"Other\", \"CST\"]\n",
    "            self.label = torch.cat([self.brain_mask.unsqueeze(0).float() - \\\n",
    "                                    self.tract_masks[2:3], self.tract_masks[2:3]], \\\n",
    "                                   dim=0).bool()\n",
    "        elif set == 2:\n",
    "            cfg['labels'] = [\"Other\", \"CG\", \"CST\", \"FX\", \"CC\"]\n",
    "            self.label = self.tract_masks[:5]\n",
    "        elif set == 3:\n",
    "            cfg['labels'] = [\"Other\", \"IFO_left\", \"IFO_right\", \"ILF_left\", \\\n",
    "                             \"ILF_right\", \"SLF_left\", \"SLF_right\"]\n",
    "            self.label = self.tract_masks[5:]\n",
    "\n",
    "            \n",
    "        #if cfg['log']:\n",
    "        #    wandb.config.update({'labels': cfg['labels']})\n",
    "            \n",
    "        self.user = UserModel(self.label, cfg)\n",
    "            \n",
    "        # [classes, B, H, W]\n",
    "        self.annotations = None\n",
    "\n",
    "        # [B, 1, H, W]\n",
    "        self.weight = None\n",
    "\n",
    "        self.pos_weight = (len(cfg['labels'])*self.brain_mask.sum() - \\\n",
    "                           self.label.sum((1,2,3))[None, :, None, None]) / \\\n",
    "                           self.label.sum((1,2,3))[None, :, None, None]\n",
    "        \n",
    "        if self.to_gpu:\n",
    "            self.input      = self.input.to(self.cfg[\"rank\"])\n",
    "            self.label      = self.label.to(self.cfg[\"rank\"])\n",
    "            self.brain_mask = self.brain_mask.to(self.cfg[\"rank\"]) \n",
    "            self.pos_weight = self.pos_weight.to(self.cfg[\"rank\"]) \n",
    "        \n",
    "        if self.augment:\n",
    "            ### Init augmentations\n",
    "            self.inpaint = InPainting(3)\n",
    "            self.outpaint = OutPainting(5)\n",
    "            \n",
    "            ### call augmentation calculation routine here\n",
    "            self.update_painting()\n",
    "            \n",
    "        if self.localize:\n",
    "            self.grad = torch.linspace(0, 1, 145).repeat(1,145,1)\n",
    "            if self.to_gpu:\n",
    "                self.grad = self.grad.to(self.cfg['rank'])\n",
    "                \n",
    "\n",
    "    def get_index_tensor_for_batching(self) -> None:\n",
    "        # get indices for all non-empty slices by class\n",
    "        idx = torch.nonzero(self.annotations.cpu().sum(axis=(2,3)))\n",
    "        # sort indices by number of annotations per slice for each class\n",
    "        indices_sorted_num_annotations_per_class = [\n",
    "            self.annotations[c, idx[idx[:, 0]==c, 1]].sum((-1, -2)).sort(descending=True)[1]\n",
    "            for c in range(len(self.cfg['labels']))\n",
    "        ]\n",
    "        # get indices per class and sort them according to index above. If we repeat short \n",
    "        # index lists later, we make sure to repeat slices with many annotations first\n",
    "        slice_indices_per_class = [\n",
    "            idx[idx[:, 0] == c, 1][indices_sorted_num_annotations_per_class[c]]\n",
    "            for c in range(len(self.cfg['labels']))\n",
    "        ]\n",
    "        # count slices per class\n",
    "        slices_per_class = [len(c) for c in slice_indices_per_class]\n",
    "        # sort classes by number of annotations. Classes with more annotations loose\n",
    "        # duplicated indices first.\n",
    "        classes_descending_by_annots = torch.Tensor(slices_per_class).sort(descending=True)[1]\n",
    "        # each slice is only used once. Class with least amount of annotations keeps\n",
    "        # the slice and its removed for every other class\n",
    "        for i, c in enumerate(classes_descending_by_annots):\n",
    "            slice_indices_per_class[c] = slice_indices_per_class[c].tolist()\n",
    "            for idx in slice_indices_per_class[c]:\n",
    "                if any(idx in slice_indices_per_class[c_] for c_ in classes_descending_by_annots[i+1:]):\n",
    "                    slice_indices_per_class[c].remove(idx)\n",
    "        # convert slices indices back to list of tensors\n",
    "        slice_indices_per_class = [torch.Tensor(c) for c in slice_indices_per_class]\n",
    "        # update the slices_per_class after removing duplicates\n",
    "        slices_per_class_short = [len(c) for c in slice_indices_per_class]\n",
    "        # save max length for cutting\n",
    "        max_length = max(slices_per_class_short)\n",
    "        # calculate how often each class index list has to be repeated to be larger\n",
    "        # than the largest class index list\n",
    "        repeat_per_class = [-(-max_length//len_) for len_ in slices_per_class_short]\n",
    "        # stack results. For each class repeat first if its not the longest list.\n",
    "        # After, cut any index that makes the list longer than the longest list, starting\n",
    "        # from the end.\n",
    "        index_tensor = torch.stack(\n",
    "            [\n",
    "                slice_idxs.repeat(repeats)[:max_length]\n",
    "#                 torch.cat(\n",
    "#                     [\n",
    "#                         slice_idxs, torch.Tensor(\n",
    "#                             [slice_idxs.repeat(2)[0]] * max_length\n",
    "#                         )\n",
    "#                     ]\n",
    "#                 )[:max_length]\n",
    "                for slice_idxs, repeats \n",
    "                in zip(slice_indices_per_class, repeat_per_class)\n",
    "            ]\n",
    "        )\n",
    "        # has shape [n_classes, length_of_longest_index_list]\n",
    "        self.index_tensor = index_tensor.long()\n",
    "                        \n",
    "\n",
    "    def permute_index_tensor(self) -> None:\n",
    "        # check if index tensor exists\n",
    "        assert self.index_tensor is not None, \"Built index tensor before permuting it\"\n",
    "        # get permuted indices for each class\n",
    "        idxs = torch.argsort(torch.rand(*self.index_tensor.shape), dim=-1)\n",
    "        # sort each class independently\n",
    "        self.index_tensor = torch.gather(self.index_tensor, dim=-1, index=idxs)\n",
    "           \n",
    "        \n",
    "    def set_mode(self, mode) -> None:\n",
    "        self.mode = mode\n",
    "\n",
    "\n",
    "    def set_modality(self, modality) -> None:\n",
    "        self.modality = modality     \n",
    "        \n",
    "        \n",
    "    def initial_annotation(self, seed=42) -> Tensor:\n",
    "        return self.user.initial_annotation(#self.label.detach().cpu(),\n",
    "                                             self.cfg[\"init_voxels\"],\n",
    "                                             init=self.init, \n",
    "                                             seed=seed)\n",
    "    \n",
    "\n",
    "    def random_refinement_annotation(self, prediction, seed=42) -> Tensor:\n",
    "        \n",
    "        if self.init == 'per_class':\n",
    "            mode = 'per_class'\n",
    "            \n",
    "        if self.init == 'three_slices':\n",
    "            mode = 'single_slice'\n",
    "\n",
    "        return self.user.random_refinement_annotation(prediction, \n",
    "                                                      self.annotations.detach().cpu(),\n",
    "                                                      self.brain_mask.detach().cpu(),\n",
    "                                                      self.cfg[\"refinement_voxels\"],\n",
    "                                                      mode=mode,\n",
    "                                                      seed=seed\n",
    "        )\n",
    "\n",
    "\n",
    "    def refinement_annotation(self, prediction, uncertainty_map=None, random=False, seed=42) -> Tensor:\n",
    "        \n",
    "        if self.init == 'per_class':\n",
    "            mode = 'per_class'\n",
    "            \n",
    "        if self.init == 'three_slices':\n",
    "            mode = 'single_slice'\n",
    "        \n",
    "        if random:\n",
    "            return self.user.random_refinement_annotation(prediction, \n",
    "                                                          self.annotations.detach().cpu(),\n",
    "                                                          self.brain_mask.detach().cpu(),\n",
    "                                                          self.cfg[\"refinement_voxels\"],\n",
    "                                                          mode=mode,\n",
    "                                                          seed=seed\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            return self.user.refinement_annotation(prediction,\n",
    "                                               #self.label.detach().cpu(),\n",
    "                                               self.annotations.detach().cpu(),\n",
    "                                               uncertainty_map,\n",
    "                                               self.cfg[\"refinement_voxels\"],\n",
    "                                               mode=mode,\n",
    "                                               seed=seed)\n",
    "\n",
    "\n",
    "    def update_annotation(self, annotations) -> None:\n",
    "        assert(annotations.data.type() == 'torch.FloatTensor')\n",
    "\n",
    "        if self.to_gpu:\n",
    "            annotations = annotations.to(self.cfg[\"rank\"])\n",
    "\n",
    "        if self.annotations is None:\n",
    "            self.annotations = annotations\n",
    "        else:\n",
    "            self.annotations += annotations\n",
    "            self.annotations  = torch.clamp(self.annotations, 0, 1)\n",
    "            \n",
    "        if self.balance:\n",
    "            self.get_index_tensor_for_batching()\n",
    "            self.permute_index_tensor()\n",
    "        \n",
    "        if self.smooth_label:\n",
    "            self.smooth_annotations = (self.annotations.clone()*(1. - 0.05)) + 0.01\n",
    "        \n",
    "        # repeat(1,len(self.cfg[\"labels\"]),1,1)\n",
    "        \n",
    "        if self.balance:\n",
    "            self.weight = (self.annotations.sum(0) > 0).unsqueeze(1).float()\n",
    "            self.cls_weight = (self.weight[self.index_tensor.flatten()].sum() - \n",
    "                                 self.annotations[:, self.index_tensor.flatten()].sum((1,2,3))[None, :, None, None])\n",
    "#             self.pos_weight  = (1 -\n",
    "#                                 self.annotations[:, self.index_tensor.flatten()].sum((1,2,3))[None, :, None, None])\n",
    "            self.pos_weight = self.cls_weight / self.annotations[:, self.index_tensor.flatten()].sum((1,2,3))[None, :, None, None]\n",
    "\n",
    "        else:\n",
    "            self.weight = (self.annotations.sum(0) > 0).unsqueeze(1).float()\n",
    "            self.pos_weight  = (self.weight.sum() - self.annotations.sum((1,2,3))[None, :, None, None])\n",
    "#             self.pos_weight  = (1 - self.annotations.sum((1,2,3))[None, :, None, None])\n",
    "            self.pos_weight /= self.annotations.sum((1,2,3))[None, :, None, None]\n",
    "\n",
    "    \n",
    "    def clear_annotation(self) -> None:\n",
    "        self.annotations = None\n",
    "        \n",
    "        \n",
    "    def update_painting(self, k_in=10, k_out=15) -> None:\n",
    "        assert self.inpaint is not None, \"Init inpaint first\"\n",
    "        assert self.outpaint is not None, \"Init outpaint first\"\n",
    "        \n",
    "        self.inpaint.update()\n",
    "        self.outpaint.update()\n",
    "        \n",
    "        # Random choice between in and out painting, ramdomly applied\n",
    "        random_choice       = transforms.RandomChoice([self.inpaint, self.outpaint])\n",
    "        random_apply_lambda = lambda slc: random_choice(slc) if torch.rand(1) > 0.1 else slc\n",
    "        self.transform      = transforms.Lambda(random_apply_lambda)\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, index) -> dict:\n",
    "        if self.balance:\n",
    "            input_ = self.input[self.index_tensor[:, index]]\n",
    "        else:\n",
    "            input_ = self.input[index]\n",
    "            \n",
    "        if self.augment:\n",
    "            input_ = self.transform(input_)\n",
    "        \n",
    "        if self.modality == 'reconstruction':\n",
    "            target = self.input[index].detach().clone()\n",
    "            weight = 1.\n",
    "\n",
    "            if self.localize:\n",
    "                target = torch.cat([target, self.grad, self.grad.transpose(-1, -2)])\n",
    "            \n",
    "        elif self.modality == 'segmentation':\n",
    "        \n",
    "            if self.mode == 'train':\n",
    "                if self.balance:\n",
    "                    target = self.annotations[:, self.index_tensor[:, index]].detach()\n",
    "                else:\n",
    "                    target = self.annotations[:, index].detach()\n",
    "            elif self.mode == 'validate':\n",
    "                target = self.label[:, index].detach()\n",
    "                \n",
    "            if self.balance:\n",
    "                weight = self.weight[self.index_tensor[:, index]]\n",
    "            else:\n",
    "                weight = self.weight[index]\n",
    "        \n",
    "        if self.balance:\n",
    "            mask = self.brain_mask[self.index_tensor[:, index]]\n",
    "        else:\n",
    "            mask = self.brain_mask[index]\n",
    "        \n",
    "        return {'input':  input_,\n",
    "                'target': target,\n",
    "                'weight': weight, # may needs unsqueeze(0) in validate\n",
    "                'mask':   mask} \n",
    "    \n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        if self.balance:\n",
    "            return self.index_tensor.shape[1]\n",
    "        else:\n",
    "            return self.input.shape[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
