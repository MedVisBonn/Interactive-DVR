{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2226109/3993998618.py:13: DeprecationWarning: Please import `binary_erosion` from the `scipy.ndimage` namespace; the `scipy.ndimage.morphology` namespace is deprecated and will be removed in SciPy 2.0.0.\n",
      "  from scipy.ndimage.morphology import binary_erosion, binary_dilation\n",
      "/tmp/ipykernel_2226109/3993998618.py:13: DeprecationWarning: Please import `binary_dilation` from the `scipy.ndimage` namespace; the `scipy.ndimage.morphology` namespace is deprecated and will be removed in SciPy 2.0.0.\n",
      "  from scipy.ndimage.morphology import binary_erosion, binary_dilation\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "import random\n",
    "from omegaconf import OmegaConf\n",
    "from typing import Iterable, Dict, Callable, Tuple, Union, List\n",
    "from scipy.ndimage import binary_erosion, binary_dilation\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage.morphology import binary_erosion, binary_dilation\n",
    "\n",
    "\n",
    "sys.path.append('..')\n",
    "from dataset import get_eval_dataset\n",
    "from utils import get_features, evaluate_RF\n",
    "from model import get_model\n",
    "from user_model import UserModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boiler plate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config\n",
    "cfg = OmegaConf.load('../configs/eval_uncertainty.yaml')\n",
    "\n",
    "cfg.feature = False\n",
    "cfg.uncertainty_measure = 'ground-truth'\n",
    "cfg.soft_scores = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: zero -> reconstruction with spatial dim 145 and Dropout False\n",
      "\n",
      "Done. Returning model and state dict ae_feature-extractor_all_old.pt.\n",
      "\n",
      "Extracting features...\n",
      "Done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "verbose = True\n",
    "\n",
    "# get dataset\n",
    "dataset = get_eval_dataset(\n",
    "    cfg=cfg,\n",
    "    initial_annotation=True,\n",
    "    verbose=verbose\n",
    ")\n",
    "\n",
    "# get model and load state dict\n",
    "model, state_dict = get_model(\n",
    "    cfg=cfg,\n",
    "    return_state_dict=True,\n",
    "    verbose=verbose\n",
    ")\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "# get features\n",
    "features = get_features(\n",
    "    model=model,\n",
    "    dataset=dataset,\n",
    "    feature=cfg.feature,\n",
    "    verbose=verbose\n",
    ")\n",
    "\n",
    "# get results\n",
    "uncertainty_measures = [\n",
    "    cfg.uncertainty_measure\n",
    "]\n",
    "if cfg.background_bias:\n",
    "    uncertainty_measures.append('feature-distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# results of initial annotation\n",
    "scores, prediction, uncertainty_maps, uncertainty_per_class_maps, t = evaluate_RF(\n",
    "    dataset=dataset, \n",
    "    features=features, \n",
    "    cfg=cfg,\n",
    "    uncertainty_measures=uncertainty_measures\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 45\n",
      "0 95\n",
      "1 45\n",
      "1 66\n",
      "0 22\n"
     ]
    }
   ],
   "source": [
    "dataset.user = UserModel(dataset.label, 'uniform', soft_scores=cfg.soft_scores, cfg=cfg)\n",
    "\n",
    "uncertainty_measure = uncertainty_measures[0]\n",
    "u_annots, _ = dataset.user.refinement_annotation(\n",
    "    prediction=prediction,\n",
    "    annotation_mask=dataset.annotations.detach().cpu(),\n",
    "    uncertainty_map=uncertainty_per_class_maps[uncertainty_measure] if uncertainty_measure != 'ground-truth' else None,\n",
    "    n_samples=200,\n",
    "    mode='per_class',\n",
    "    seed=42,\n",
    "    inverse_class_freq=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros((10,10)).numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "UserModel.__init__() missing 1 required positional argument: 'cfg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m dataset\u001b[38;5;241m.\u001b[39muser \u001b[38;5;241m=\u001b[39m \u001b[43mUserModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43muniform\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m dataset\u001b[38;5;241m.\u001b[39minit \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mper_class\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# currently, there are no annotations. We can also enforce this with clear_annotations() at any point\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: UserModel.__init__() missing 1 required positional argument: 'cfg'"
     ]
    }
   ],
   "source": [
    "dataset.user = UserModel(dataset.label, 'uniform', cfg)\n",
    "dataset.init = 'per_class'\n",
    "# currently, there are no annotations. We can also enforce this with clear_annotations() at any point\n",
    "dataset.clear_annotation()\n",
    "# get initial annotations\n",
    "annot = dataset.initial_annotation(seed=42)\n",
    "# and update the dataset\n",
    "dataset.update_annotation(annot)\n",
    "print(f\"number of annotations: {dataset.annotations.detach().cpu().sum()}\")\n",
    "cached_annots = dataset.annotations.clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
